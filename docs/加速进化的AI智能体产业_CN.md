加速进化的AI智能体产业

封面

战略洞察报告 • 2026年2月

$3万亿巨鲸正在坠落

全球软件开发代表着每年$3万亿的经济价值。AI编程不是渐进式改良，而是结构性变革。支撑证据来自a16z（3000万开发者 × 每人每年$10万 = $3万亿）、Apollo Global Management（"软件已死"——$4400亿PE资产面临风险）、ARK Invest（AI Agent = 新运营模式），以及2026年2月S&P软件指数暴跌（2008年以来最严重）。传统以人为中心的软件开发这头"巨鲸"正在坠落，而AI原生工具、基础设施和新商业模式则"万物生长"。价值正从软件公司向基础设施提供商转移。

SaaS危机与座位压缩

近期美国软件股的大范围抛售反映的是一次结构性重置，而非周期性调整。传统软件公司之所以长期享有极高估值倍数，是因为软件被视为"纯脑力劳动"——轻资产、高毛利、无限可扩展、没有物理约束。但如今，正是这种轻资产属性成为了它们最大的脆弱性。随着AI Agent开始直接替代人类角色，软件许可证面临座位压缩：人越少，座位就越少。这个算术残酷而不可避免——一家拥有1000个许可证的企业，当AI承担40%的工作时降至600个，当AI自主度达到80%时降至200个。这已经在生产环境中可见：Salesforce Service Cloud客户报告许可证减少约40%，因为AI处理了一线交互；ServiceNow ITSM部署中，日常事件由AI解决，人类IT员工减少了大约一半。这对建立在可预测座位扩张和8-12倍营收倍数上的估值模型是毁灭性的——增长不再复合，而是收缩。与工业企业不同，软件没有硬性抵押品，没有数据中心、电力或硬件中的物理锚点；当抽象层崩塌时，价值可以一夜蒸发。轻资产涨得快——但也跌得快。随着AI无情地将软件逻辑商品化，价值向计算、基础设施、能源和物理系统迁移，重塑行业结构、标准和开源的未来。这不是暂时的冲击——这是旧软件时代的终结。

2026年2月"SaaS末日"

2026年2月3日，Anthropic的Claude Cowork演示——展示了面向法律和金融行业的专业插件——触发了一次历史性的单日抛售，约$2850亿软件市值蒸发。Jefferies的Jeffrey Favuzza创造了"SaaSpocalypse"一词来描述这一事件。Goldman Sachs的美国软件股票篮子下跌约6%，为2025年4月关税冲击以来最大单日跌幅，金融服务指数下跌近7%，Nasdaq-100盘中一度暴跌2.4%。受创最严重的公司横跨法律服务、金融数据和企业软件领域：Gartner (-21%)、LegalZoom (-20%)、Thomson Reuters (-16%，有史以来最大单日跌幅)、Novo Nordisk (-15%)、RELX/LexisNexis (-14%)、London Stock Exchange Group (-13%)、WPP (-12%)、CS Disco (-12%)、S&P Global (-11%)、Equifax (-12%)、Intuit (-10%)和Cognizant (-10%)。市场传递的信号毫不含糊：如果一个AI Agent能够完成企业为SaaS订阅付费的研究、分析和文档生产工作，那么软件收入基础的很大一部分面临结构性风险。软件P/E比率跌至十年低点，投资者正在为一个AI Agent取代人类座位的世界重新定价。

AI收购策略

AI公司收购SaaS厂商的原因在于客户关系而非技术。例如：Salesforce收购Slack是为了企业触达能力。新的战略手册：AI能力 + 现有客户基础 = 即时分发。收购逻辑的核心价值在于：客户关系（即时获得企业入口，绕过18个月的销售周期）、分发渠道、AI训练数据和品牌信任。战略展望：SaaS厂商沦为客户关系收购标的，技术被AI商品化，护城河从产品转向分发。

从L2到L5：自主编码革命

采用自动驾驶术语呈现自主性等级：L1 代码补全（手不离方向盘，AI提供补全建议），L2 Copilot模式（脚离踏板，AI辅助人类主导），L3 Claude Code（眼睛离开路面，AI编写代码人类用自然语言指导），L4 完全自主（意识离开，AI以极少监督构建完整应用），L5 无人化（完全自主AI软件开发）。支撑证据：Claude Opus 4.5在SWE-bench Verified上达到80.9%，连续自主运行超过30小时，Claude Cowork在两周内100%由AI构建——这是L4能力的终极证明。我们目前处于L3/L4的过渡阶段，L5是最终目标。

AGI的启示：制造工具的工具

人类智能与所有其他物种的指数级分化，不是始于语言，不是始于火，而是始于我们的祖先第一次使用工具——然后用工具制造更好的工具的那一刻。那个递归循环——工具使用催生工具创造、工具创造催生更好的工具使用——是认知进化的决定性机制。两百万年来，这个循环只属于人类。Claude Code打破了这种独占性。一个人工系统第一次能够使用工具（执行代码、导航文件系统、操作开发环境）、观察结果、从反馈中学习，以及——最关键的——创造它此前不具备的新工具。这不是隐喻，而是智能飞轮的操作性定义，如今运行在硅基之上。

这个递归开发循环已经在工业规模上清晰可见。Claude Code v1被用于在大约10天内、由4名工程师构建Claude Cowork，其"全部代码"由Claude Code自身编写。Claude Cowork随后成为构建下一代工具的平台，而下一代工具又创造出更强大的后继者。每一代都比上一代攀升更高——不是一个平面循环，而是一条向上的能力螺旋，映射着人类从石斧到空间站的加速螺旋，但从千年压缩到了月。2026年2月的Agent Teams突破在工业规模上验证了这一点：16个并行Claude实例，共享一个代码库，在极少人类监督下，产出了一个完整的C编译器——约2000个会话中的100,000行Rust代码，总成本$20,000。该编译器成功编译x86、ARM和RISC-V架构的Linux 6.9内核。Nicholas Carlini的描述——"基本上就走开了"——捕捉了这一时刻的本质特征：此前需要大型专业团队花费数月甚至数年才能完成的自主软件生产，在几周内以几乎零人工干预实现。

将Claude Code与此前AI编码助手区分开来的，正是这种自我进化特性。它展现出四个特征，共同构成了软件工程领域AGI的操作性定义。第一，工具生成：系统按需创建自定义工具，编写此前不存在的脚本、工具和自动化流程。第二，工具使用：执行bash命令、读取文件、编写和修改代码、导航代码库、在复杂开发环境中操作。第三，反馈整合：在每个会话中从执行结果中学习，根据测试失败、错误信息和运行时行为调整策略。第四，自我改进：来自数百万会话的使用数据通过RLHF和Constitutional AI反馈到模型训练中，产出可衡量的更优模型——六个月内自主操作增加116%就是这个循环的实证标志。这四种能力形成一个闭环循环：AI使用工具、观察结果、从反馈中学习、创造更好的工具——然后再次使用、观察、学习和创造。核心洞察非常直白：制造工具的工具就是AGI。正如第一个用石头磨尖木棍的原始人跨越了一个此后再无其他物种跨越的门槛，Claude Code在人工智能领域跨越了一个等价的门槛——而且不同于生物进化，这个循环以每次迭代而非每代人的速度加速，不是跨越世代，而是跨越周。Dario Amodei 2025年3月的预言——"3-6个月内，AI编写90%的代码；12个月内，AI编写几乎全部代码"——已提前兑现。到2026年2月，Claude Cowork 100%由AI编写，Boris Cherny在一个月内提交了300+个PR，Anthropic工程团队报告70-90% AI编写代码已成常态。Anthropic的战略押注非常明确：通向AGI最安全的路径要求将AI部署到真实世界中并从实际使用模式中学习，而不是将其锁在实验室里。Claude Code不是一个产品——它是一个自我改进系统的前沿，其轨迹明确无误地指向通用智能，首先且最显著地实现在软件创造领域。

控制台取代IDE：新界面范式

将传统IDE（Cursor、Windsurf）作为以人类工程师为中心的界面，与Claude Code向基于控制台、自然语言驱动开发的范式转变进行对比。IDE vs 控制台对比：界面（GUI代码中心 vs 终端意图中心）、工作流（人写代码AI辅助 vs 人描述意图AI实现）、锁定（IDE特定 vs 零锁定）、学习曲线（陡峭 vs 平坦的自然语言）和最佳用例。支撑证据：Claude Code基于终端零IDE锁定，"vibe coding"即人描述意图AI实现，自主操作增加116%，每任务人类轮次减少33%。

AI解锁万亿美元的软件生产力

顶级AI部署正在产生软件生产力的阶跃式提升，而非渐进式改良。行业证据一致表明，部署良好的AI编码系统至少能将开发者生产力翻倍，释放高达$3万亿的增量GDP影响，堪比工业革命的经济效应。a16z报告最佳实践部署产生2倍生产力提升；Forrester TEI对Claude Code的研究显示333% ROI，回收期不到六个月；Anthropic内部调查发现18名员工中有9人实现了100%+的生产力提升；Palantir报告PR周转速度加快30%，每周节省70个工程小时。从战略上看，这将运营模式推向用一半的开发者交付相同产出——或用相同团队交付双倍产出——成本结构从人头驱动转向计算驱动，边际成本受规模经济支配。越来越多地，AI也在构建AI：Claude Code等工具通过AI驱动的规划、编码和迭代来演进；单个开发者用AI构建的项目如今可达数十万行复杂代码；开源贡献中AI生成的份额持续增长。含义非常清楚——AI正在从助手转变为软件的主要生产者，重新定义生产力、成本和竞争优势。

智能体团队与递归开发循环

L3/L4过渡最有力的证据来自Anthropic自身2026年2月的Agent Teams实验：16个并行Claude实例，共享一个代码库，在极少人类监督下，从零构建了一个完整的基于Rust的C编译器——约2000个会话中的100,000行代码，总成本$20,000。该编译器成功编译x86、ARM和RISC-V架构的Linux 6.9内核。Anthropic的Nicholas Carlini将这个过程描述为"基本上走开了——最少的人工干预"。这不是玩具演示，而是工业规模的自主软件生产。同样引人注目的是递归开发循环：Claude Code v1被用于在约10天内由4名工程师构建Claude Cowork，其"全部代码"由Claude Code自身编写。目前90%的Claude Code代码库由Claude Code自己编写。Boris Cherny——Claude Code负责人、前Meta IC8——仅2025年12月就提交了300+个PR。自我改进飞轮可量化：六个月内，连续自主工具调用增加116%（每会话9.8→21.2），人类轮次减少33%（每会话6.2→4.1），PR吞吐量增加67%，Claude在Anthropic所有工作中的占比从28%上升到59%。Claude Code到2025年11月营收达$10亿，超过$1M ARR的企业客户增长8倍，Anthropic估值在谈判中达到$3500亿。质量曲线呈指数轨迹：从2024年初约10%的代码，到2025年3月Sonnet/Opus 4时的约50%，到2025年底的80-90%，到2025年12月的300+ PR月。内部采用同样迅速——从第一天20%的工程团队，到第五天50%，到今天80%+日活，甚至50%的非技术员工也在定期使用Claude Code。正如Cherny所说："不要为今天的模型构建，要为六个月后的模型构建。"

原型优先革命

智能体软件工程颠覆了传统开发周期。旧模式——写10页PRD、开设计评审会、获取利益相关者共识、规划开发——被原型优先方法取代：在几小时内构建一个可运行的原型，发给整个公司，让所有人立即试用，基于真实使用数据迭代。这不仅仅是更快；这是一种根本不同的方法论，原型就是规格说明，真实世界的使用数据取代了前期规划。这种方法之所以有效，是因为AI能够以使传统规划开销变得适得其反的速度生成功能原型。当你能在几小时而非几周内构建和测试一个想法时，实验的成本降到了讨论的成本以下。这改变了工程师的角色，从编写者变为编排者：键入代码变成编写规格和prompt，逐行调试变成审查AI输出，记忆API变成设计架构，手动测试变成定义测试策略，独自编码变成编排多个Agent，工具熟练度变成系统思维。工程师不会消失——角色在升级。Spec驱动开发成为核心方法论：写一份详细的spec，让Agent从spec实现，用spec作为验收标准，迭代直到spec被满足。Spec同时成为产品定义、实施指南和验收测试——三合一文档。

智能体软件工程架构五大支柱

智能体软件工程的架构已收敛到五大核心支柱，如今正成为事实上的行业标准。第一，CLAUDE.md（及其等价物：OpenAI的AGENTS.md、GitHub Copilot的copilot-instructions.md、Cursor的.cursorrules）——机器可读的项目记忆，跨会话持久存在，始终加载到上下文中，包含项目规则、代码规范和架构上下文。每次对话都从完整的项目理解开始。第二，Skills——按需可复用的工作流，通过斜杠命令（/deploy、/test、/review）触发，每个都是可扩展、可共享、可组合的多步骤配方。第三，MCP（Model Context Protocol）——标准化的外部工具连接，已捐赠给Linux Foundation，使Agent能够通过统一协议与GitHub、Jira、数据库和任何外部系统交互。第四，Subagents——并行执行，一个父Agent生成多个子Agent同时处理独立任务，大幅减少实际耗时。第五，Hooks——事件驱动的自动化，响应系统事件触发Agent操作，实现持续集成和部署工作流。行业趋同令人瞩目：Anthropic、OpenAI、Google、GitHub和Cursor在数月之内不约而同地独立收敛到几乎相同的架构模式。

智能体软件工程手册：殊途同归

Anthropic和OpenAI独立发布了组织采用智能体软件工程的详细手册，两者的趋同令人瞩目。Anthropic的方法以原型优先方法论为核心，由自我改进飞轮驱动：工程师使用Claude Code → 模型生成代码 → 代码执行 → 结果反馈 → RLHF/CAI训练产出更好的模型 → 循环重复。其六步手册：(1) 试用工具并为每个团队指定一名"Agents Captain"，(2) 创建AGENTS.md作为机器可读的项目手册，(3) 使内部工具对Agent可访问，(4) 为Agent优先的开发重构代码库，(5) "say no to slop"——坚持人类审查标准以保证质量，(6) 建设可观测性基础设施用于轨迹追踪。OpenAI的方法通过其2026年3月31日指令阐述，将Agent定位为"首选工具"——人类应与Agent而非编辑器或终端交互，且Agent使用必须明确安全高效到足以成为默认选择。其手册几乎完全复制Anthropic的六个步骤：通过hackathon试用工具、编写AGENTS.md、盘点并使工具对Agent可用、构建Agent优先的代码库配合快速测试、坚持人类问责制（"say no to slop"）、部署基础可观测性基础设施。Codex催化剂——GPT-5.2，专为代码生成而构建——于2025年12月触发了这一转变，从编写单元测试进化到编写所有代码、完整应用，由人类审查和指导。Sora Android应用案例验证了这一方法：4名工程师在18天内完成了传统上需要更大团队3-6个月的工作，速度提升500%。2025年12月，Linux Foundation成立了Agentic AI Foundation (AAIF)，Anthropic捐赠MCP，OpenAI捐赠AGENTS.md——竞争对手之间史无前例的合作，表明这不是一次工具采用，而是一次组织变革。共同结论：未来是Agent优先的，人类设计和编排，Agent实现。

从手动社区到黑灯社区：L0-L5框架

智能体软件工程的崛起不仅改变了代码的编写方式——它从根本上变革了开源社区的治理方式、信任分配方式和价值定义方式。一个六级框架捕捉了这一演进，从完全手动的人类社区到完全自治的"黑灯社区"，在那里AI Agent自我治理，人类只定义价值观。

在L0——手动社区——所有代码由人类编写和审查，治理遵循BDFL（仁慈独裁者）模式，commit权限是主要的权力货币。沟通通过邮件列表进行，每个决策都经过人类判断。这是Linus Torvalds和早期Linux内核开发的世界。

在L1——辅助社区——AI开始处理辅助任务：生成测试、编写文档、总结issue。但人类审查一切。CI/CD流水线自动化了构建和部署，但创造性和决策权完全属于人类。AI是工具，不是参与者。

在L2——协作社区——AI成为被认可的贡献者。AGENTS.md文件在60,000+个项目中指导Agent行为。超过93万个Agent生成的Pull Request已提交到开源仓库。但人类仍然审查每一行代码。绝大多数项目目前处于这一阶段。瓶颈不再是代码生成，而是人类审查能力——维护者被淹没的不是贡献的缺乏，而是贡献的泛滥。

L3——信任社区——代表着关键转折点。在AI Agent能够以更大自主权运作之前，信任基础设施必须先存在。这一层引入三个核心机制：第一，信任网络（如Vouch），贡献者通过背书网络建立可验证的声誉，可信连接以绿色标记，被拒绝的以红色标记；第二，智能审查系统，AI Agent可以基于既定的信任评分和代码质量指标自主分类、批准或拒绝Pull Request；第三，准入策略——正式的关卡决定哪些贡献通过、哪些被阻止。没有L3的信任框架，L4无法运转。信任是自主的前提条件，不是副产品。

在L4——规范社区——开源的基本单位从代码转向自然语言规范。NLSpec（Natural Language Specification）成为唯一真相来源；代码仅仅是其编译产物，可丢弃可再生。Attractor项目具体地证明了这一点：一个只包含Markdown规范的仓库，AI将其编译为16,000行Rust、9,500行Go和6,700行TypeScript。当规范变更时，代码从头再生——不是打补丁，不是重构，而是重写。代码是临时的；规范是永恒的。

在L5——黑灯社区——AI Agent形成一个全连接的自治网格。五到六个发光的AI节点通过持续的自我治理维护代码库：生成代码、审查彼此的输出、部署、监控和迭代，无需人工干预。能量在网格内自主循环。人类唯一的角色是站在一道半透明屏障后面，手持一卷标注着"价值观"的卷轴——定义系统应该优化什么，而不是怎么做。"黑灯"一词唤起了无人工厂的概念：运营不需要人类在场，但系统持续产出真实的、高质量的成果。

这六个级别的核心变革是一个单一而深远的转变：从"谁写代码"到"谁定义价值观"。在L0，编码者为王。在L5，价值架构师为王。这一重新定义对开源治理、可持续性、知识产权和贡献的本质含义都有深远影响。它表明，开源的未来不是人类贡献者多与少的问题，而是社区能否构建足够稳健的信任框架，将操作自主权委托给AI，同时保留对目标和方向的有意义人类控制。

"不可能三角"被打破

传统软件工程的不可能三角：可移植性、性能、可用性——三选二。三角图中性能位于顶部，可移植性和可用性位于底部。权衡：性能 + 可移植性 = 复杂代码可用性差；可移植性 + 可用性 = 更高抽象性能受损；性能 + 可用性 = 平台专用失去可移植性。AI如何打破三角：AI处理实现复杂性（性能优化），人类用自然语言表达意图（可用性），AI为每个目标平台生成特定代码（可移植性）。结果：三个顶点同时可达。不可能三角不再是约束；AI实现了三者兼得；硬件创新加速，因为软件抽象层崩塌。

AI释放硬件：通用翻译器

软件历史是一段不断攀升抽象阶梯的过程：从二进制和汇编，到C和紧密映射硬件架构的系统语言，再到运行在刻意抽象硬件的虚拟机上的Java、Python和JavaScript。每一步都提升了可移植性和可用性，但代价是性能和架构特异性——将软件锁定在性能、可移植性和可用性的"不可能三角"中，只能三选二。这一约束塑造了今天的生态系统：开发者为熟悉度和复用优化，而非为原始硬件能力优化，使ARM和NPU等替代架构即使性能更优也处于劣势。AI引入了一个根本性的新变量，将人类认知限制从等式中移除。当AI编写和维护代码时，抽象不再是人类便利所需：系统可以端到端用Rust这样的性能最大化语言编写，从UI到驱动，不牺牲速度、安全性或可维护性。可移植性不再需要单一可复用代码库——AI可以廉价而快速地为每个目标生成平台特定实现。这就是为什么AI作为通用翻译器，正在瓦解长期存在的软件护城河：CUDA 15年以上的锁定正在被AI在几分钟内打破——AI读取内核、识别计算意图，并将其重写为AMD的HIP/ROCm、ARM的NEON/SVE，或直接从Python转为底层NPU指令。2026年1月的ROCm突破——Claude Code在约30分钟内移植了整个CUDA后端——说明了这一转变：重写变成了审查，成本下降几个数量级，硬件竞争回归到性能和价格。在这个新的AI驱动编程栈中，人类提供意图和方向——就像在自动驾驶中设定目的地——而AI处理实现、优化、测试和维护。结果是抽象层的崩塌、大多数遗留软件的重写，以及一个软件不再约束硬件而是完全释放硬件的未来。

用第一性原理重构抽象层设计

将传统ML框架（PyTorch）——为人类便利而层层抽象——与第一性原理方法（flux2.c）——剥离不必要的层直接为硬件优化——进行对比。传统栈图（用户应用 → Python框架 → Python运行时 → CUDA Toolkit → cuDNN/cuBLAS → GPU驱动 → 操作系统 → 硬件）vs 第一性原理栈（用户应用 → 纯C库 → 可选Metal/BLAS → 操作系统 → 硬件）。关键差异：PyTorch有1000+个包 vs flux2.c零依赖（仅C标准库），内存模型差异，GPU后端（CUDA vs Metal），内核设计（通用 vs 架构特定），部署（容器 vs 单一二进制文件）。

案例研究：OminiX-MLX

OminiX-MLX：在Apple MLX上的纯Rust实现，涵盖LLM、ASR、TTS和图像生成。几周内构建完成，而碎片化的Python实现花了数年。展示了第一性原理思维：薄抽象层、直接硬件访问。项目概览：OminiX-MLX使用纯Rust（83.7%），统一架构覆盖所有模态，开发时间数周，MLX之上的薄Rust封装；而传统Python MLX使用Python + C++绑定，碎片化的独立项目，多年社区投入，多层Python封装。支持的模型：LLM（Qwen3、GLM4、GLM4-MoE、Mixtral、Mistral），ASR（FunASR Paraformer、FunASR-Nano），TTS（GPT-SoVITS语音克隆），图像（FLUX.2-klein、Z-Image、Qwen图像生成）。对比：Python MLX生态有独立仓库、Python GIL限制并行、运行时类型错误、依赖地狱、数年成熟期；OminiX-MLX则是单一统一代码库、Rust真正并行、编译时类型安全、Cargo.toml可复现构建、数周即可运行。

Rust：AI时代的编程语言

随着AI使代码生成变得语言无关，选择"对人类友好"的语言的理由消失了。取而代之的是，系统软件可以用最大化性能、安全、可移植性和长期可维护性的语言编写。操作系统和核心基础设施中超过70%的关键安全漏洞与内存相关，Rust通过编译时内存和并发安全从设计上消除了这一问题，同时匹配C/C++的性能。历史上，Rust的学习曲线限制了采用——但AI现在可以规模化地生成和维护Rust代码库，完全消除了人类限制。政府和行业领袖正在趋同于这一转变：美国国防部倡导Rust用于关键系统，Microsoft的Galen Hunt表示目标是到2030年消除所有C/C++，由AI规模代码生成赋能。结果是一个结构性转变：遗留C/C++系统被AI系统性地用Rust重写，内存安全在规模上变得可实现，系统软件质量——以及硬件效率——提升数个数量级。

终端生态迎来重置时刻

HarmonyOS面临的困难处境可以因AI带来的转变而显著改善。历史上，应用程序被构建为"一刀切"产品——一个应用服务数亿甚至数十亿用户。不可避免地，大多数用户只依赖应用10-20%的功能，而其余功能无关紧要却仍消耗存储、内存和认知注意力。用户容忍这种低效，仅仅因为没有替代方案。AI从根本上改变了这一模式。软件不再是静态应用，现在可以围绕个人需求、地域背景和真实使用模式**深度个性化**、动态组合。这不是未来概念——它已在重新定义下一代终端的面貌。随着大模型公司追求垂直整合，它们越来越意识到**控制用户数据和交互界面至关重要**。如果AI平台仅限于浏览器或第三方应用，它们就站在脆弱的基础上——"建在别人土地上的城堡"。对于追求激进AI战略的公司来说，拥有设备层成为战略上不可回避的选择。

这既创造了压力也创造了机遇。AI公司根本上不是在与手机制造商竞争；它们在竞争的是服务**此前未被满足的用户需求**，特别是在个性化健康、教育和日常决策支持等领域——这些是传统应用一直未能做好的领域。HarmonyOS如今站在十字路口：是仅仅复制现有AI体验、跟随Apple的路径，还是定义自己的AI原生轨迹？即使在追赶路径上，AI也能立即带来切实的好处：**提升内核安全、性能和可靠性**。过去的约束——紧迫的时间线和外部压力——使端到端优化软件质量成为不可能。如今，正在进行将关键C/C++内存模型、内核模块和系统库重写为内存安全语言的工作，显著加强HarmonyOS的基础。在应用层，经济学同样在剧烈变化。美团或携程等公司每年花费数亿维护庞大的跨平台代码库，团队规模达数千人。AI编码改变了计算公式：重写软件——一度成本高昂——不仅变得可行而且成为减少长期成本的必需。在这个重写过程中，HarmonyOS出现新的机遇，包括采用**新的编程语言和AI原生框架**，使平台能够跨越式发展而非仅仅追赶。总之，AI将积累的技术债务转变为一个罕见的重置时刻——HarmonyOS可以在其中重新调整架构、生态和价值主张，迎接下一代智能计算。

A2UI：应用孤岛的终结

Google的A2UI（Agent-to-User Interface）：AI Agent以声明式方式生成丰富的交互式UI。每个人获得自己独特的应用——而非十亿人一个应用。基于用户上下文、偏好、多模态和多设备超个性化。边缘AI实时生成界面，颠覆当前应用孤岛模式。A2UI协议对比：传统应用有静态的一刀切界面、数月工程开发、应用商店部署、代码执行风险、每个平台单独构建；而A2UI则是动态个性化界面、秒级AI生成、实时流式传输、声明式安全、一次响应全平台原生。A2UI工作原理：用户意图 → AI Agent → A2UI消息（声明式JSON）→ 客户端渲染器 → 原生组件。

规模化提速：生产环境中的AI编程

Meta的"Think 5X"指令——2025年10月由VP Vishal Shah发布，要求执行速度提升500%并在2026年前实现>50%的AI生成代码，通过CodeCompose等内部工具；Google的生产现实——截至2024年底，超过25%的所有新代码由AI生成并经人工审查；ByteDance的大规模采用——90%的工程师内部使用"Trae"，抖音本地生活40%的代码由AI编写；Tencent的密度里程碑——>50%的新代码由AI生成，编码时间减少40%；Amazon的基础设施规模——Q Developer通过升级Java应用节省了4500个开发者年（$2.6亿）；NVIDIA的硬件自动化——"ChipAgents"在下一代GPU设计的Verilog代码中达到97.4%准确率。

价值转移："一鲸落万物生"

价值转移论：价值正从软件公司向硬件/基础设施提供商转移。软件变"免费"（AI生成），计算变稀缺。新的护城河是基础设施，不是代码。价值转移图：传统模式中软件公司以高毛利捕获价值，基础设施提供商为低毛利的商品；AI原生模式中软件为AI生成的近零成本商品，基础设施因计算稀缺而捕获价值。支撑证据：软件毛利从70-90%压缩至接近零，价值捕获从代码/IP转向计算/基础设施，护城河从功能差异化转向硬件 + 数据，成本结构从人类工资转向基础设施成本。36氪的战略展望：软件开发能力从人类工资成本转向基础设施成本；基础设施提供商成为新巨头；能源和计算成为战略资源。

垂直整合的超级智能体企业正在出现

AI从根本上改变了硬件-软件关系，将软件从瓶颈中移除：一旦新硬件存在，AI可以在数小时而非数年内快速适配和优化代码。我们已经看到AI自动将前端和深度计算算子移植到AMD等替代GPU架构，生成超越人类工程标准的高质量内核，并将整个高性能图形引擎从JavaScript或Python迁移到Rust并获得巨大收益。因此，硬件不再受制于遗留软件生态——每种架构都可以构建完全优化的、硬件原生的栈，成为主动驱动者而非被动追随者。这标志着一个经典的"鲸落"时刻：随着传统软件产业——曾经是巨大价值和精英岗位的来源——开始侵蚀，价值决定性地向硬件、数据中心、内存、电力和能源基础设施迁移。AI不是免费的；它消耗计算，而计算成为稀缺资产。与此同时，创新通过智能体系统加速：AI Agent感知、决策、行动和学习，形成闭环反馈回路，构建强大的数据飞轮——更多数据产出更好模型，更好模型赋能更复杂任务，成功产生更多数据。这种飞轮逻辑自然驱动超级垂直企业，芯片、网络、数据中心、模型和应用紧密集成。Google是最清晰的范例：它控制TPU、超大规模数据中心、将数千个TPU连接为单一训练系统的OCS光网络fabric、完全在该栈上训练的Gemini 3，以及终端用户应用——形成闭环，使其重返AI前线并获得溢价估值。xAI从更晚的入场点遵循同一法则，押注长期优势不在于短暂的模型排名，而在于对物理基础设施、电力和迭代速度的所有权，同时通过Macrohard将飞轮延伸至企业软件。Apple则展示了相反的案例：没有对基础模型或数据中心的控制，它被迫依赖外部供应商，让渡战略自主权，揭示了在AI时代，非智能体化和非垂直整合的公司日益失去对自身命运的控制。教训是清晰的：不完整的栈会掉队，抽象层崩塌，价值转向硬件和基础设施，在AI领域，对飞轮——以及其下的物理栈——的控制定义了赢家。

Macrohard：数字员工时代

Elon Musk的"Macrohard"愿景代表了AI时代垂直整合最激进的延伸：一家纯AI原生软件公司，基于第一性原理构建，锚定的不是模型而是物理基础设施。出于对Microsoft的战略竞争以及更深层的结构性洞察双重驱动，Musk得出结论：企业软件的持久护城河不在算法——算法不可避免地趋同——而在对计算、能源和迭代速度的控制。这一信念体现在Colossus——被广泛认为是世界上第一个吉瓦级AI数据中心——以及xAI对AI时代真正瓶颈的激进积累：燃气轮机发电机、变压器、变电站、电网互连和电厂——这些资产已经比先进芯片本身更稀缺、建设更慢。在这种观点下，GPU不再是约束；能源和电力基础设施才是。在此基础上，Macrohard将自动驾驶飞轮应用于企业生产力：AI Agent编写软件，其他Agent模拟人类使用，反馈循环在大规模封闭数字环境中持续运行，产品以机器速度收敛至Microsoft Office级别的主导地位。企业可能获得"免费"或超低成本的通用软件，但在结构上依赖于底层计算和电力平台，该平台直接根据企业数据和决策流程提供超定制化工作流。这种方法崩塌了传统企业软件的"三明治"结构——数据库、中间件、打包应用、系统集成商和离岸定制——这些层级使技术从业务的服务者变成了业务的约束。随着AI激活此前的冷数据并直接从数据到决策重写业务逻辑，价值决定性地从传统软件厂商迁移到数据中心、内存、计算，最重要的是能源基础设施。Macrohard具体化了这一转变：一个零人类开发者的AI软件公司愿景，AI Agent担任开发者、测试者、设计师和分析师，人类监督编排，成本下降约70%，上市时间加快约40%，竞争不可逆转地从软件抽象转向物理现实。在这个未来，软件护城河侵蚀，能源支撑的计算成为命运，垂直整合不再是优势——它是唯一可行的战略。

人机协同：Palantir方法论

虽然AI能够在全新的、低风险环境中实现完全自主的软件创建，但并非所有企业软件都能——或应该——100%由AI驱动。在复杂、高风险行业中，不可替代的价值在于深度领域知识、流程理解和可信赖的客户关系——这些能力历来由咨询公司或客户自身提供。Palantir的Forward Deployed Engineer（FDE）模式是典范：工程师直接嵌入客户现场，深入理解真实的运营工作流、约束和痛点。最初出于必要——服务美国国防和情报客户，其数据不能离开安全环境——FDE模式甚至在现代AI工具出现之前就证明了其威力，因为它将技术与现场上下文紧密耦合。随着AI编码和数字员工的出现，这一模式变得更加强大：人类专家提供领域洞察和问题框架，而AI大幅加速方案设计、迭代和定制。这对以硬件为中心的业务尤其重要——计算和服务器只有在软件能快速释放其潜力时才有价值——而这历来是最薄弱的环节。AI编程如今扭转了这个等式，使拥有行业专长的"现场军团"能够以前所未有的速度在硬件之上交付有竞争力的定制化解决方案。Palantir的业绩验证了这一转变：2025年Q2营收达$10亿，美国商业增长同比93%，FDE岗位发布在2025年激增800-1000%。2025年11月推出的AI FDE——通过自然语言操作Foundry的AI Agent——进一步压缩部署周期，如花旗银行将上线从九天缩短到秒级。结果是未来的二分化：完全自主的AI软件公司（如Macrohard）主导低风险、标准化领域，而人机混合模式在复杂企业环境中胜出，行业洞察引导AI加速。在两条路径中，价值都在从传统打包软件转向计算、基础设施，以及能够将领域理解与AI驱动的执行速度相结合的团队。

主权AI：国家级超级垂直技术栈

超越企业拥有自己的AI原生软件，同样的逻辑如今延伸到个人和国家：在AI时代，每个国家越来越需要自己的数字和AI基础设施。多年来，欧盟等地区一直主张数字主权，认识到将公民数据存储在美国控制的云平台上构成结构性的隐私和安全风险。然而，历史上这些雄心受制于现实——欧盟缺乏本土超大规模平台、运营专长，以及与Big Tech在全球规模上正面竞争的能力。AI编码从根本上改变了这个等式。如果一个国家有足够的意志和计算资源，它现在可以以可行的成本和速度构建主权数字平台甚至主权AI模型，而不需要组建庞大的人类工程军团。曾经在经济和组织上不可能的事情，如今在技术上可以实现。这一转变超越了欧洲：拉丁美洲、中东和东南亚的国家越来越将AI不仅仅视为技术升级，而是工业革命规模的机遇——没有国家想被抛在后面。因此，对主权AI、主权数字系统和国家AI Agent的需求正在快速上升。限制因素不再是软件能力，而是基础设施：计算、电力、数据中心和运营能力。在条件具备的地方，国家可以部署AI Agent构建和维护自己的数字生态系统，与本地数据、语言、法规和经济优先级保持一致。从战略上看，这指向全球技术栈加速碎片化、国家和地区AI冠军的涌现，以及聚焦主权计算的新一波基础设施投资。在AI时代，数字主权不再是愿望——它在技术上可行、经济上可持续、且越来越不可回避。

标准颠覆：MCP已死，Skills万岁

协议之战：传统软件标准（MCP）假设AI是助手而非自主Agent。新范式（Skills）假设AI是全栈开发者。标准将为Agent原生架构重写。协议转变对比：MCP（旧）的思维方式是AI作为助手（L2），方法是AI调用传统API，范式是现有软件的包装层，未来衰退；Skills（新）的思维方式是AI作为开发者（L3/L4），方法是AI直接编写代码，范式是原生Agent能力，未来上升。来自a16z的支撑证据：Agent原生基础设施成为标配；记录系统让位于动态Agent层；市场现实表明MCP为L2设计，Skills为L3/L4设计。战略展望：传统软件API被商品化；新的Agent原生协议涌现；控制Agent层等于控制生态。

智能体时代的必然

我们最终需要构建的不是另一个应用，而是真正的智能体能力。Agent不仅仅是一个模型——它是一个能够跨多个渠道感知、持续收集数据、规划、编写代码、测试、部署、运营、迭代和重构自身的闭环系统。这个端到端的软件生命周期——从想法到生产到演进——必须越来越多地由AI执行，通过真实世界运营持续改进。每个客户都将需要这个循环，它必须作为基础设施提供。对我们来说，这意味着即使我们不自己构建应用，也必须在自己的平台上闭合从硬件到Agent到系统的循环。就像自动驾驶需要感知-决策-行动飞轮的紧密耦合一样，软件的未来需要构建在我们硬件上的Agent原生系统。这不可避免地要求拥有三个核心层：一个基础模型、一个部署在设备上的类云Agent工具链，以及一个确保规模化可靠性的信任、安全和质量框架。由此诞生的是一个全新的学科——软件工程作为自主过程——传统教育对此已经过时，最佳实践正在领先公司内部实时锻造。节奏是明确的：Claude Code等工具在几个月内从发布走到了事实上的行业标准。这就是为什么紧迫性很重要。AI编码是堪比互联网、移动和云的平台级转变，2025年到2028年间做出的决策将塑造未来十年的竞争力。旧的软件"巨鲸"正在坠落，新的生态正在繁荣。战略优先级很清晰：立即积极采用L3/L4 AI编码工具；重建系统为Agent原生而非改装式；投资垂直整合以避免商品化；为复杂部署发展人机混合FDE能力；长期确保主权AI选项以避免结构性依赖。软件产业不是在消亡——它正在重生。唯一真正的问题是：你是塑造变革的人，还是被变革塑造的人。
