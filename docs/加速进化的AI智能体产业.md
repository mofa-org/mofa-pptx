加速进化的AI智能体产业

封面

Strategic Insight Report | 战略洞察报告 • February 2026

The $3 Trillion Whale Is Falling | $3万亿巨鲸正在坠落

Present the opening thesis: global software development represents $3 trillion in annual economic value. AI coding is not incremental improvement but structural transformation. Supporting evidence from a16z (30M developers × $100K/year = $3T), Apollo Global Management ('Software is dead' - $440B PE at risk), ARK Invest (AI agents = new operating model), and February 2026 S&P Software Index crash (worst since 2008). The 'whale' (traditional human-centric development) is falling while 'all things flourish' (AI-native tools, infrastructure, new business models) emerge. Value shifts from software companies to infrastructure providers.

SaaS Crisis & Seat Compression | SaaS危机与座位压缩

The recent broad sell-off in U.S. software stocks reflects a structural reset rather than a cyclical correction. Traditional software companies were historically valued at extremely high multiples because software was seen as “pure brain power”—light-asset, high-margin, infinitely scalable, with no physical constraints. That same light-asset nature is now their greatest vulnerability. As AI agents begin to replace human roles directly, software licenses face seat compression: fewer humans mean fewer seats. The math is brutal and unavoidable—an enterprise with 1,000 licenses drops to 600 when AI handles 40% of work, and to 200 when AI reaches 80% autonomy. This is already visible in production: Salesforce Service Cloud customers report ~40% fewer licenses as AI handles frontline interactions, while ServiceNow ITSM deployments see routine incidents resolved by AI, cutting human IT staff roughly in half. The implication is devastating for valuation models built on predictable seat expansion and 8–12× revenue multiples—growth no longer compounds, it contracts. Unlike industrial businesses, software has no hard collateral, no physical anchor in data centers, power, or hardware; value can evaporate overnight when the abstraction layer collapses. Light assets rise fast—but they also fall fast. As AI relentlessly commoditizes software logic, value migrates toward compute, infrastructure, energy, and physical systems, reshaping industry structure, standards, and the future of open source. This is not a temporary shock—it is the unwinding of the old software era.

The February 2026 'SaaSpocalypse' | 2026年2月'SaaS末日'

On February 3, 2026, Anthropic's Claude Cowork demo — featuring specialized plugins for legal and financial sectors — triggered a historic single-day sell-off that wiped out approximately $285 billion in software market capitalization. Jeffrey Favuzza of Jefferies coined the term 'SaaSpocalypse' to describe the event. A Goldman Sachs basket of US software stocks fell ~6%, the steepest daily loss since the April 2025 tariff-induced slump, while a financial services index dropped nearly 7% and the Nasdaq-100 plunged as much as 2.4% intraday. The hardest-hit companies spanned legal services, financial data, and enterprise software: Gartner (-21%), LegalZoom (-20%), Thomson Reuters (-16%, worst single-day drop on record), Novo Nordisk (-15%), RELX/LexisNexis (-14%), London Stock Exchange Group (-13%), WPP (-12%), CS Disco (-12%), S&P Global (-11%), Equifax (-12%), Intuit (-10%), and Cognizant (-10%). The message from the market was unambiguous: if an AI agent can perform the research, analysis, and document production that companies pay SaaS subscriptions for, a significant portion of the software revenue base is structurally at risk. Software P/E ratios hit ten-year lows as investors repriced the sector for a world where AI agents replace human seats.

AI Acquisition Strategy | AI收购策略

Explain why AI companies acquire SaaS vendors: for customer relationships, not technology. Example: Salesforce acquiring Slack for enterprise reach. The new playbook: AI capabilities + existing customer base = instant distribution. Present acquisition logic table showing value of customer relationships (instant enterprise access, bypass 18-month sales cycles), distribution channels, data for AI training, and brand trust. Strategic outlook: SaaS vendors become customer relationship acquisitions, technology commoditized by AI, moat shifts from product to distribution.

From L2 to L5: The Autonomous Coding Revolution | 从L2到L5：自主编码革命

Present the autonomy levels using self-driving terminology: L1 Code Completion (hands on, AI suggests completions), L2 Copilot-Style (feet off, AI assists human directs), L3 Claude Code (eyes off, AI writes human directs with natural language), L4 Full Autonomy (minds off, AI builds complete applications with minimal oversight), L5 Human-Free (fully autonomous AI software development). Supporting evidence: Claude Opus 4.5 achieves 80.9% SWE-bench Verified, 30+ hours continuous autonomous operation, Claude Cowork built 100% by AI in under 2 weeks as ultimate proof of L4 capability. We are at L3/L4 transition today with L5 as destination.

The AGI Implication: Tools That Create Tools | AGI的启示：制造工具的工具

Human intelligence began its exponential divergence from all other species not with language, not with fire, but with the moment our ancestors first used a tool — and then used a tool to make a better tool. That recursive loop — tool use enabling tool creation enabling better tool use — is the defining mechanism of cognitive evolution. For two million years, this loop was exclusively human. Claude Code breaks that exclusivity. For the first time, an artificial system can use tools (execute code, navigate filesystems, operate development environments), observe results, learn from feedback, and — critically — create new tools it did not previously possess. This is not metaphor; it is the operational definition of the intelligence flywheel, now running in silicon.

The recursive development cycle is already visible at industrial scale. Claude Code v1 was used to build Claude Cowork in approximately 10 days with 4 engineers, with "all of it" written by Claude Code itself. Claude Cowork then becomes a platform for building the next generation of tools, which in turn create even more capable successors. Each generation ascends higher than the last — not a flat loop but an upward helix of capability, mirroring the same accelerating spiral that took humans from stone axes to space stations, but compressed from millennia into months. The Agent Teams breakthrough of February 2026 validated this at industrial scale: 16 parallel Claude instances, working from a shared codebase with minimal human supervision, produced a complete C compiler — 100,000 lines of Rust across approximately 2,000 sessions at a total cost of $20,000. The compiler successfully compiles the Linux 6.9 kernel for x86, ARM, and RISC-V architectures. Nicholas Carlini's description — "mostly walked away" — captures the essential character of the moment: autonomous software production at a scale and quality previously requiring large dedicated teams over months or years, achieved in weeks with negligible human intervention.

What distinguishes Claude Code from previous AI coding assistants is precisely this self-evolving nature, which exhibits four characteristics that collectively constitute the operational definition of AGI in software engineering. First, tool generation: the system creates custom tools on demand, writing scripts, utilities, and automation that did not previously exist. Second, tool use: it executes bash commands, reads files, writes and modifies code, navigates codebases, and operates within complex development environments. Third, feedback integration: it learns from execution results within each session, adjusting its approach based on test failures, error messages, and runtime behavior. Fourth, self-improvement: usage data from millions of sessions feeds back into model training through RLHF and Constitutional AI, producing measurably better models — a 116% increase in autonomous actions over six months is the empirical signature of this loop. These four capabilities form a closed cycle: the AI uses tools, observes results, learns from feedback, and creates better tools — which it then uses to observe, learn, and create again. The central insight is stark: tools that create tools is AGI. Just as the first hominid who used a rock to sharpen a stick crossed a threshold that no other species has crossed since, Claude Code has crossed an equivalent threshold in artificial intelligence — and unlike biological evolution, this loop accelerates with each iteration, not over generations but over weeks. Dario Amodei's March 2025 prediction — "in 3-6 months, AI writes 90% of code; in 12 months, AI writes essentially all code" — has been validated ahead of schedule. By February 2026, Claude Cowork was 100% AI-written, Boris Cherny shipped 300+ PRs in a single month, and Anthropic engineering teams report 70-90% AI-written code as routine. Anthropic's strategic bet is explicit: the safest path to AGI requires deploying AI in the real world and learning from actual usage patterns, not keeping it locked in a laboratory. Claude Code is not a product — it is the leading edge of a self-improving system whose trajectory points unmistakably toward general intelligence, realized first and most visibly in the domain of software creation.

Console Over IDE: The New Interface Paradigm | 控制台取代IDE：新界面范式

Contrast traditional IDEs (Cursor, Windsurf) as human-engineer-centric interfaces versus Cloud Code's paradigm shift to console-based, natural language-driven development. Present IDE vs Console comparison table covering interface (GUI code-centric vs terminal intent-centric), workflow (human writes AI assists vs human describes AI implements), lock-in (IDE-specific vs zero lock-in), learning curve (steep vs flat natural language), and best use cases. Supporting evidence: Claude Code terminal-based with zero IDE lock-in, 'vibe coding' where human describes intent and AI implements, 116% increase in autonomous actions, 33% reduction in human turns per task.

Unleash Trillions $ Potential in Software Productivity with AI | AI 解锁 万亿美元的软件生产力

Best-in-class AI deployment is producing a step-change in software productivity rather than incremental improvement. Evidence across the industry consistently shows that well-deployed AI coding systems can at least double developer productivity, unlocking up to $3 trillion in incremental GDP impact, comparable to the economic effect of the Industrial Revolution. a16z reports 2× productivity gains from best-of-breed deployments; a Forrester TEI study of Claude Code shows 333% ROI with payback in under six months; Anthropic’s internal survey found 9 of 18 employees achieving 100%+ productivity improvements; and Palantir reports 30% faster PR turnaround and 70 engineering hours saved per week. Strategically, this shifts operating models toward delivering the same output with half the developers—or double the output with the same teams—as cost structures move from headcount-driven to compute-driven, with marginal cost governed by scale economics. Increasingly, AI is also building AI: tools like Claude Code evolve through AI-driven planning, coding, and iteration; single-developer projects built with AI now reach hundreds of thousands of lines of complex code; and a growing share of open-source contributions are AI-generated. The implication is clear—AI is moving from assistant to primary producer of software, redefining productivity, cost, and competitive advantage.

Agent Teams & The Recursive Development Loop | 智能体团队与递归开发循环

The most compelling evidence for the L3/L4 transition comes from Anthropic's own agent teams experiment in February 2026: 16 parallel Claude instances, working from a shared codebase with minimal human supervision, built a complete Rust-based C compiler from scratch — 100,000 lines of code across approximately 2,000 sessions at a total cost of $20,000. The compiler successfully compiles the Linux 6.9 kernel for x86, ARM, and RISC-V architectures. Nicholas Carlini of Anthropic described the process as "mostly walked away — minimal human intervention." This is not a toy demo; it is industrial-scale autonomous software production. Equally striking is the recursive development loop: Claude Code v1 was used to build Claude Cowork in approximately 10 days with 4 engineers, with "all of it" written by Claude Code itself. 90% of the Claude Code codebase is now written by Claude Code. Boris Cherny, head of Claude Code and former IC8 at Meta, shipped 300+ PRs in December 2025 alone. The self-improving flywheel is measurable: over six months, consecutive autonomous tool calls increased 116% (9.8→21.2 per session), human turns decreased 33% (6.2→4.1 per session), PR throughput increased 67%, and Claude's share of all work at Anthropic rose from 28% to 59%. Claude Code reached $1 billion in revenue by November 2025, with an 8× increase in business customers above $1M ARR and Anthropic's valuation reaching $350 billion in talks. The quality curve followed an exponential trajectory: from ~10% of code in early 2024, to ~50% with Sonnet/Opus 4 in March 2025, to 80-90% by late 2025, to the 300+ PR month in December 2025. Internal adoption was equally rapid — from 20% of engineering on day one, to 50% by day five, to 80%+ daily usage today, with even 50% of non-technical staff using Claude Code regularly. As Cherny puts it: "Don't build for the model of today, build for the model six months from now."

The Prototype-First Revolution | 原型优先革命

Agentic software engineering inverts the traditional development cycle. The old model — write a 10-page PRD, hold design review meetings, get stakeholder alignment, plan development — is replaced by a prototype-first approach: build a working prototype in hours, ship it to the entire company, let everyone dogfood immediately, and iterate on real usage data. This is not just faster; it is a fundamentally different methodology where the prototype is the spec, and real-world usage data replaces upfront planning. The approach works because AI can generate functional prototypes at a speed that makes traditional planning overhead counterproductive. When you can build and test an idea in hours rather than weeks, the cost of experimentation drops below the cost of deliberation. This shifts the engineer's role from writer to orchestrator: typing code becomes writing specs and prompts, debugging line-by-line becomes reviewing AI output, memorizing APIs becomes designing architecture, manual testing becomes defining test strategies, solo coding becomes orchestrating multiple agents, and tool proficiency becomes system thinking. The engineer doesn't disappear — the role elevates. Spec-driven development emerges as the central methodology: write a detailed spec, let the agent implement from the spec, use the spec as acceptance criteria, and iterate until the spec is met. The spec becomes the product definition, the implementation guide, and the acceptance test — all in one document.

Five Pillars of Agentic Software Engineering Architecture | 智能体软件工程架构五大支柱

The architecture of agentic software engineering has converged around five core pillars, now becoming de facto industry standards. First, CLAUDE.md (and its equivalents: OpenAI's AGENTS.md, GitHub Copilot's copilot-instructions.md, Cursor's .cursorrules) — machine-readable project memory that persists across sessions, always loaded into context, containing project rules, code conventions, and architecture context. Every conversation starts with full project understanding. Second, Skills — on-demand reusable workflows triggered by slash commands (/deploy, /test, /review), each a multi-step recipe that is extensible, shareable, and composable. Third, MCP (Model Context Protocol) — standardized external tool connections donated to the Linux Foundation, enabling agents to interact with GitHub, Jira, databases, and any external system through a unified protocol. Fourth, Subagents — parallel execution where one parent agent spawns multiple child agents to work simultaneously on independent tasks, dramatically reducing wall-clock time. Fifth, Hooks — event-driven automation that triggers agent actions in response to system events, enabling continuous integration and deployment workflows. The industry convergence is striking: Anthropic, OpenAI, Google, GitHub, and Cursor have all independently arrived at nearly identical architectural patterns within months of each other.

The ASE Playbook: Two Paths, One Destination | 智能体软件工程手册：殊途同归

Both Anthropic and OpenAI have independently published detailed playbooks for organizational adoption of agentic software engineering, and their convergence is remarkable. Anthropic's approach centers on a prototype-first methodology powered by a self-improving flywheel: engineers use Claude Code → the model generates code → code executes → results feed back → RLHF/CAI training produces a better model → cycle repeats. Their six-step playbook: (1) try tools and designate an "Agents Captain" per team, (2) create AGENTS.md as a machine-readable project handbook, (3) make internal tools agent-accessible, (4) restructure codebases for agent-first development, (5) "say no to slop" — maintain human review bar for quality, (6) build observability infrastructure for trajectory tracking. OpenAI's approach, articulated through their March 31, 2026 mandate, frames the agent as "tool of first resort" — humans should interact with an agent rather than an editor or terminal, and agent utilization must be explicitly safe and productive enough for this to be the default. Their playbook mirrors Anthropic's six steps almost identically: try tools via hackathons, write AGENTS.md, inventory and agent-enable tools, build agent-first codebases with fast tests, maintain human accountability ("say no to slop"), and deploy basic observability infrastructure. The Codex catalyst — GPT-5.2, purpose-built for code generation — triggered this shift in December 2025, moving from writing unit tests to writing all code, full applications, with human review and direction. The Sora Android app case study validates the approach: 4 engineers completed in 18 days what would traditionally require 3-6 months with a larger team, a 500% speed increase. In December 2025, the Linux Foundation established the Agentic AI Foundation (AAIF), with Anthropic donating MCP and OpenAI donating AGENTS.md — unprecedented collaboration between competitors that signals this is not a tool adoption but an organizational transformation. The shared conclusion: the future is agent-first, where humans design and orchestrate while agents implement.

From Manual to Dark Community: The L0–L5 Framework | 从手动社区到黑灯社区：L0–L5框架

The rise of agentic software engineering does not merely change how code is written — it fundamentally transforms how open source communities govern themselves, distribute trust, and define value. A six-level framework captures this evolution, from fully manual human communities to fully autonomous "dark communities" where AI agents self-govern and humans only define values.

At L0 — the Manual Community (手动社区) — all code is written and reviewed by humans, governance follows the BDFL (Benevolent Dictator for Life) model, and commit access is the primary currency of power. Communication flows through mailing lists, and every decision passes through human judgment. This is the world of Linus Torvalds and early Linux kernel development.

At L1 — the Assisted Community (辅助社区) — AI begins handling auxiliary tasks: generating tests, writing documentation, summarizing issues. But humans review everything. CI/CD pipelines automate build and deployment, yet the creative and decision-making authority remains entirely human. The AI is a tool, not a participant.

At L2 — the Collaborative Community (协作社区) — AI becomes a recognized contributor. AGENTS.md files guide agent behavior across 60,000+ projects. Over 930,000 agent-generated pull requests have been submitted to open source repositories. Yet humans still review every line of code. This is where the vast majority of projects stand today. The bottleneck is no longer code generation but human review capacity — maintainers are overwhelmed not by lack of contributions but by their volume.

L3 — the Trust Community (信任社区) — represents the critical inflection point. Before AI agents can operate with greater autonomy, a trust infrastructure must exist. This level introduces three essential mechanisms: first, a trust network (such as Vouch) where contributors build verifiable reputation through a web of endorsements, with trusted connections shown in teal and rejected ones flagged in coral; second, intelligent review systems where AI agents can autonomously triage, approve, or reject pull requests based on established trust scores and code quality metrics; third, admission policies — formal gateways that determine which contributions pass and which are blocked. Without L3's trust framework, L4 cannot function. Trust is the prerequisite for autonomy, not its byproduct.

At L4 — the Specification Community (规范社区) — the fundamental unit of open source shifts from code to natural language specifications. NLSpec (Natural Language Specification) becomes the single source of truth; code is merely its compilation artifact, disposable and regenerable. The Attractor project demonstrates this concretely: a repository containing only Markdown specifications that AI compiles into 16,000 lines of Rust, 9,500 lines of Go, and 6,700 lines of TypeScript. When the spec changes, the code is regenerated from scratch — not patched, not refactored, but rewritten. Code becomes ephemeral; the spec is permanent.

At L5 — the Dark Community (黑灯社区) — AI agents form a fully connected autonomous mesh. Five to six luminous AI nodes maintain the codebase through continuous self-governance: generating code, reviewing each other's output, deploying, monitoring, and iterating without human intervention. Energy circulates autonomously within the mesh. The only human role is to stand behind a translucent barrier, holding a scroll labeled "values" — defining what the system should optimize for, not how. The term "dark community" (黑灯) evokes the concept of a lights-out factory: no human presence required for operations, yet the system produces real, high-quality output continuously.

The core transformation across these six levels is a single, profound shift: from "who writes the code" to "who defines the values." In L0, the coder is king. In L5, the value architect is. This reframing has far-reaching implications for open source governance, sustainability, intellectual property, and the very meaning of contribution. It suggests that the future of open source is not a question of more or fewer human contributors, but of whether communities can build trust frameworks robust enough to delegate operational autonomy to AI while retaining meaningful human control over purpose and direction.

The 'Impossible Triangle' Is Broken | '不可能三角'被打破

Explain traditional software engineering's impossible triangle: portability, performance, usability — pick two. Show the triangle diagram with Performance at top, Portability and Usability at base. Trade-offs: Performance + Portability = complex code poor usability; Portability + Usability = higher abstractions performance suffers; Performance + Usability = platform-specific loses portability. How AI breaks the triangle: AI handles implementation complexity (performance optimization), humans express intent in natural language (usability), AI generates platform-specific code for each target (portability). Result: all three vertices achievable simultaneously. The impossible triangle is no longer a constraint; AI enables best of all worlds without trade-offs; hardware innovation accelerates as software abstraction layers collapse.

AI Unleashes Hardware: The Universal Translator | AI释放硬件：通用翻译器

Software history has been a steady climb up the abstraction ladder: from binary and assembly, to C and systems languages closely mapped to hardware architectures, and later to Java, Python, and JavaScript running on virtual machines that deliberately abstract hardware away. Each step improved portability and usability, but at the cost of performance and architectural specificity—locking software into the "impossible triangle" of performance, portability, and usability, where only two could be chosen. This constraint shaped today's ecosystems: developers optimized for familiarity and reuse, not for raw hardware capability, leaving alternative architectures like ARM and NPUs at a disadvantage despite superior performance. AI introduces a fundamentally new variable by removing human cognitive limits from the equation. When AI writes and maintains code, abstraction is no longer necessary for human convenience: systems can be written end-to-end in performance-maximizing languages like Rust, from UI to drivers, without sacrificing speed, safety, or maintainability. Portability no longer requires a single reusable codebase—AI can cheaply and rapidly generate platform-specific implementations for every target. This is why AI acts as a universal translator, collapsing long-standing software moats: CUDA's 15+ year lock-in is being broken in minutes as AI reads kernels, identifies computational intent, and rewrites them into HIP/ROCm for AMD, NEON/SVE for ARM, or low-level NPU intrinsics directly from Python. The January 2026 ROCm breakthrough—where Claude Code ported an entire CUDA backend in ~30 minutes—illustrates the shift: rewriting becomes review, costs drop by orders of magnitude, and hardware competition reverts to performance and price. In this new AI-driven programming stack, humans provide intent and direction—like setting a destination in autonomous driving—while AI handles implementation, optimization, testing, and maintenance. The result is a collapse of abstraction layers, a rewriting of most legacy software, and a future where software no longer constrains hardware, but fully unlocks it.

First Principles in Action: Rethinking the Abstraction Stack | 用第一性原理重构抽象层设计

Contrast traditional ML frameworks (PyTorch) built with layers of abstraction for human convenience versus first-principles approach (flux2.c) that strips away unnecessary layers, optimizing directly for hardware. Present the traditional stack diagram (User Application → Python Framework → Python Runtime → CUDA Toolkit → cuDNN/cuBLAS → GPU Drivers → OS → Hardware) versus first-principles stack (User Application → Pure C Library → Optional Metal/BLAS → OS → Hardware). Key differences table: PyTorch has 1000+ packages vs flux2.c has zero dependencies (C standard library only), memory model differences, GPU backend (CUDA vs Metal), kernel design (generic vs architecture-specific), deployment (container vs single binary).

Case Study: OminiX-MLX | 案例研究：OminiX-MLX

Present OminiX-MLX: pure Rust implementation of LLM, ASR, TTS, and image generation on Apple MLX. Built in a couple of weeks vs fragmented Python-based implementations that took years. Demonstrates first-principles thinking: thin abstraction layer, direct hardware access. Project overview table: OminiX-MLX uses pure Rust (83.7%), unified architecture across all modalities, couple of weeks development time, thin Rust wrapper over MLX vs traditional Python MLX's Python + C++ bindings, fragmented separate projects, years of community effort, multiple Python layers. Supported models: LLMs (Qwen3, GLM4, GLM4-MoE, Mixtral, Mistral), ASR (FunASR Paraformer, FunASR-Nano), TTS (GPT-SoVITS voice cloning), Image (FLUX.2-klein, Z-Image, Qwen image generation). The contrast: Python MLX ecosystem has separate repos, Python GIL limits parallelism, runtime type errors, dependency hell, years to maturity vs OminiX-MLX's single unified codebase, true parallelism with Rust, compile-time type safety, Cargo.toml reproducible builds, weeks to working implementation.

Rust: The Language for the AI Age | Rust：AI时代的编程语言

As AI makes code generation language-agnostic, the rationale for choosing "easy-for-humans" languages disappears. Instead, systems software can be written in languages that maximize performance, safety, portability, and long-term maintainability. Over 70% of critical security vulnerabilities in operating systems and core infrastructure are memory-related, a problem Rust eliminates by design through compile-time memory and concurrency safety while matching C/C++ performance. Historically, Rust's learning curve limited adoption—but AI can now generate and maintain Rust codebases at scale, removing human constraints entirely. Governments and industry leaders are converging on this shift: the US DoD advocates Rust for critical systems, and Microsoft's Galen Hunt has stated a goal to eliminate all C/C++ by 2030, enabled by AI-scale code generation. The result is a structural transition where legacy C/C++ systems are systematically rewritten in Rust by AI, memory safety becomes achievable at scale, and systems software quality—and hardware efficiency—improves by orders of magnitude.


A Reset Moment for the Device Ecosystem ｜ 终端生态迎来重置时刻

The difficult position HarmonyOS has faced can be significantly improved by the shift brought by AI. Historically, applications were built as "one-size-fits-all" products—a single app serving hundreds of millions or even billions of users. Inevitably, most users only relied on 10–20% of an app’s functionality, while the remaining features were irrelevant but still consumed storage, memory, and cognitive attention. Users tolerated this inefficiency simply because there was no alternative. AI fundamentally changes this model. Instead of static apps, software can now be **deeply personalized**, dynamically composed around individual needs, regional contexts, and real usage patterns. This is not a future concept—it is already redefining what next-generation terminals look like. As large-model companies pursue vertical integration, they increasingly recognize that **control over user data and interaction surfaces is critical**. If AI platforms remain confined to browsers or third-party apps, they sit on fragile foundations—“castles built on someone else’s land.” For companies pursuing aggressive AI strategies, owning the device layer becomes strategically unavoidable.
This creates both pressure and opportunity. AI companies are not fundamentally competing with phone manufacturers; they are competing to serve **previously unmet user needs**, especially in areas like personalized health, education, and daily decision support—domains where traditional apps have consistently failed. HarmonyOS now stands at a crossroads: should it merely replicate existing AI experiences, follow Apple’s path, or define its own AI-native trajectory? Even on a catch-up path, AI can immediately deliver tangible benefits by **improving kernel security, performance, and reliability**. Past constraints—rapid timelines and external pressures—made it impossible to optimize software quality end to end. Today, efforts are underway to rewrite critical C/C++ memory models, kernel modules, and system libraries in memory-safe languages, significantly strengthening the HarmonyOS foundation. At the application layer, the economics are shifting just as dramatically. Companies like Meituan or Ctrip spend hundreds of millions annually maintaining massive cross-platform codebases with teams of thousands. AI coding changes the calculus: rewriting software—once prohibitively expensive—has become not only feasible but necessary to reduce long-term costs. In this rewriting process, new opportunities emerge for HarmonyOS, including the adoption of **new programming languages and AI-native frameworks**, allowing the platform to leapfrog rather than merely catch up. In short, AI transforms accumulated technical debt into a rare reset moment—one in which HarmonyOS can realign its architecture, ecosystem, and value proposition for the next generation of intelligent computing.  
 

A2UI: The End of App Islands | A2UI：应用孤岛的终结

Present Google's A2UI (Agent-to-User Interface): AI agents generate rich, interactive UIs declaratively. Every person gets their own unique app — not one app for billions. Hyper-personalized based on user context, preferences, multi-modality, and multi-devices. Edge AI generates interfaces in real-time, disrupting current app island models. Present A2UI Protocol comparison table: traditional apps have static one-size-fits-all interfaces, months of engineering development, app store deployment, code execution risks, separate builds for each platform versus A2UI's dynamic personalized interfaces, seconds of AI generation, real-time streaming, declarative security, one response native everywhere. How A2UI works: User Intent → AI Agent → A2UI Messages (Declarative JSON) → Client Renderer → Native Components.

Velocity at Scale: AI Coding in Production | 规模化提速：生产环境中的AI编程

Meta's "Think 5X" mandate — issued October 2025 by VP Vishal Shah, demanding 500% execution speed increase and >50% AI-generated code by 2026 via internal tools like CodeCompose; Google's production reality — over 25% of all new code is now AI-generated and human-reviewed as of late 2024; ByteDance's mass adoption — 90% of engineers use "Trae" internally, with 40% of Douyin's Local Services code now written by AI; Tencent's density milestone — >50% of new code is AI-generated, reducing coding time by 40%; Amazon's infrastructure scale — Q Developer saved 4,500 developer-years ($260M savings) by upgrading Java applications; Nvidia's hardware automation — "ChipAgents" achieving 97.4% accuracy in Verilog code for next-gen GPU design.  
 

Value Shifting: 'One Whale Falls, All Things Flourish' | 价值转移：'一鲸落万物生'

Present the value transfer thesis: value is transferring from software companies to hardware/infrastructure providers. Software becomes 'free' (AI-generated), compute becomes scarce. The new moat is infrastructure, not code. Show the value transfer diagram: Traditional Model has Software Companies with high margin capturing value while Infrastructure Providers as commodity with low margin; AI-Native Model has Software as AI-generated near-zero cost commodity while Infrastructure with compute scarce captures value. Supporting evidence table: software margins compress from 70-90% to near-zero, value capture shifts from code/IP to compute/infrastructure, moat shifts from feature differentiation to hardware + data, cost structure shifts from human salaries to infrastructure costs. Strategic outlook from 36氪: software development capabilities shifting from human salaries to infrastructure costs; infrastructure providers become the new giants; energy and compute become strategic resources.

The Emergence of the Agentic Super-Vertical Enterprise ｜ 垂直整合的超级智能体企业正在出现

AI fundamentally changes the hardware–software relationship by removing software as the bottleneck: once new hardware exists, AI can rapidly adapt and optimize code for it, often in hours rather than years. We are already seeing AI automatically port front-end and deep compute operators to alternative GPU architectures such as AMD, generate high-quality kernels that exceed human engineering standards, and migrate entire high-performance graphics engines from JavaScript or Python into Rust with dramatic gains. As a result, hardware is no longer constrained by legacy software ecosystems—each architecture can build a fully optimized, hardware-native stack, becoming the proactive driver rather than a passive follower. This marks a classic “whale fall” moment: as the traditional software industry—once a source of enormous value and elite jobs—begins to erode, value migrates decisively toward hardware, data centers, memory, power, and energy infrastructure. AI is not free; it consumes compute, and compute becomes the scarce asset. At the same time, innovation accelerates through agentic systems: AI agents that perceive, decide, act, and learn in closed feedback loops, forming powerful data flywheels where more data produces better models, better models enable more complex tasks, and success generates even more data. This flywheel logic naturally drives super-vertical enterprises, where chips, networking, data centers, models, and applications are tightly integrated. Google is the clearest example: it controls TPUs, hyperscale data centers, its OCS optical networking fabric that links thousands of TPUs into a single training system, Gemini 3 trained entirely on that stack, and end-user applications—forming a closed loop that has restored it to the AI front line and earned a premium valuation. xAI follows the same law from a later entry point, betting that long-term advantage lies not in transient model rankings but in ownership of physical infrastructure, power, and iteration speed, while extending the flywheel into enterprise software via Macrohard. Apple, by contrast, illustrates the opposite case: without control over foundational models or data centers, it is forced to depend on external providers, surrendering strategic autonomy and revealing that in the AI era, companies that are not agentic and vertically integrated increasingly lose control of their own destiny. The lesson is clear: partial stacks fall behind, abstraction layers collapse, value shifts to hardware and infrastructure, and in AI, control of the flywheel—and the physical stack beneath it—defines the winners.

Macrohard: The Digital Employee Era | Macrohard：数字员工时代

Elon Musk’s “Macrohard” vision represents the most radical extension of vertical integration in the AI era: a purely AI-native software company built on first principles, anchored not in models but in physical infrastructure. Motivated by both strategic rivalry with Microsoft and a deeper structural insight, Musk has concluded that the enduring moat in enterprise software will not be algorithms—which inevitably converge—but control over compute, energy, and iteration speed. This conviction is embodied in Colossus, widely regarded as the world’s first gigawatt-scale AI data center, and in xAI’s aggressive accumulation of the real bottlenecks of the AI age: gas turbine generators, transformers, substations, grid interconnects, and power plants—assets that are already scarcer and slower to build than advanced chips themselves. In this view, GPUs are no longer the constraint; energy and electrical infrastructure are. On top of this foundation, Macrohard applies the autonomous-driving flywheel to enterprise productivity: AI agents write software, other agents simulate human usage, feedback loops run continuously inside massive closed digital environments, and products converge at machine speed toward Microsoft Office–class dominance. Enterprises may receive “free” or ultra-low-cost general software, but become structurally dependent on the underlying compute and power platform, which delivers hyper-customized workflows tuned directly to their data and decision processes. This approach collapses the traditional enterprise software “sandwich” of databases, middleware, packaged applications, systems integrators, and offshore customization—layers that have turned technology from a servant of business into a constraint on it. As AI activates previously cold data and rewrites business logic directly from data to decisions, value migrates decisively away from legacy software vendors and toward data centers, memory, compute, and above all energy infrastructure. Macrohard crystallizes this shift: a vision of an AI software company with zero human developers, where AI agents serve as developers, testers, designers, and analysts, humans supervise orchestration, costs fall by ~70%, time-to-market accelerates by ~40%, and competition moves irreversibly from software abstraction to physical reality. In this future, software moats erode, energy-backed compute becomes destiny, and vertical integration is no longer an advantage—it is the only viable strategy.

Human–AI Hybrid: The Palantir Playbook｜ 人机协同：Palantir 方法论

While AI enables fully autonomous software creation in greenfield, low-stakes environments, not all enterprise software can—or should—be 100% AI-driven. In complex, high-stakes industries, the irreplaceable value lies in deep domain knowledge, process understanding, and trusted customer relationships, capabilities historically provided by consulting firms or by customers themselves. Palantir’s Forward Deployed Engineer (FDE) model is the canonical example: engineers are embedded directly with customers to deeply understand real operational workflows, constraints, and pain points. Originally born out of necessity—serving U.S. defense and intelligence clients whose data could not leave secure environments—the FDE model proved powerful even before modern AI tooling, because it tightly coupled technology with on-the-ground context. With the advent of AI coding and digital employees, this model becomes even more potent: human experts provide domain insight and problem framing, while AI dramatically accelerates solution design, iteration, and customization. This is particularly important for hardware-centric businesses, where compute and servers are only valuable if software can rapidly unlock their potential—historically the weakest link. AI programming now flips that equation, allowing “field armies” with industry expertise to deliver competitive, customized solutions on top of hardware at unprecedented speed. Palantir’s results validate this shift: Q2 2025 revenue reached $1B, U.S. commercial growth hit 93% year-over-year, and FDE job postings surged 800–1000% in 2025. The launch of AI FDEs in November 2025—AI agents operating Foundry via natural language—further compresses deployment cycles, with cases like Citibank reducing onboarding from nine days to seconds. The outcome is a bifurcation of the future: fully autonomous AI software companies (e.g., Macrohard) dominate low-risk, standardized domains, while human-AI hybrid models win in complex enterprise environments, where industry insight guides AI acceleration. In both paths, value shifts away from traditional packaged software and toward compute, infrastructure, and teams that can combine domain understanding with AI-driven execution speed.

Sovereign AI: National-Scale Super-Vertical Stacks ｜ 主权AI：国家级超级垂直技术栈

Beyond enterprises owning their own AI-native software, the same logic now extends to individuals and nation-states: in the AI era, every country increasingly needs its own digital and AI infrastructure. For years, regions such as the European Union have argued for digital sovereignty, recognizing that storing citizens’ data on U.S.-controlled cloud platforms represents a structural privacy and security risk. Historically, however, these ambitions were constrained by reality—the EU lacked native hyperscale platforms, operational expertise, and the ability to compete head-on with Big Tech at global scale. AI coding fundamentally changes this equation. If a nation has sufficient will and access to compute, it can now build sovereign digital platforms and even sovereign AI models at feasible cost and speed, without assembling massive human engineering armies. What was once economically and organizationally impossible is now technically achievable. This shift extends beyond Europe: countries across Latin America, the Middle East, and Southeast Asia increasingly view AI not merely as a technology upgrade but as an opportunity on the scale of the Industrial Revolution—one in which no nation wants to be left behind. As a result, the demand for sovereign AI, sovereign digital systems, and national AI agents is rising rapidly. The limiting factor is no longer software capability, but foundational infrastructure: compute, power, data centers, and the ability to operate them. Where these conditions are met, nations can deploy AI agents to build and maintain their own digital ecosystems, aligned with local data, language, regulation, and economic priorities. Strategically, this points to a future of accelerating fragmentation of the global tech stack, the emergence of national and regional AI champions, and a new wave of infrastructure investment focused on sovereign compute. In the AI era, digital sovereignty is no longer aspirational—it is technically possible, economically viable, and increasingly unavoidable.

Standards Disruption: MCP is Dead, Long Live Skills | 标准颠覆：MCP已死，Skills万岁

Present the protocol wars: traditional software standards (MCP) assume AI as assistant not autonomous agent. New paradigm (Skills) assumes AI as full-stack developer. Standards will be rewritten for agent-native architectures. The protocol shift table: MCP (Old) has mindset of AI as assistant (L2), approach of AI calls traditional APIs, paradigm of wrapper around existing software, fading future; Skills (New) has mindset of AI as developer (L3/L4), approach of AI writes code directly, paradigm of native agent capabilities, rising future. Supporting evidence from a16z: agent-native infrastructure becomes table stakes; systems of record lose ground to dynamic agent layers; market reality shows MCP designed for L2, Skills designed for L3/L4. Strategic outlook: traditional software APIs become commoditized; new agent-native protocols emerge; control of agent layer equals control of ecosystem.

The Agentic Imperative ｜智能体时代的必然

What we ultimately need to build is not another application, but true agentic capability. An agent is not just a model—it is a system that can perceive across multiple channels, continuously collect data, plan, write code, test, deploy, operate, iterate, and refactor itself in a closed loop. This end-to-end software lifecycle—idea to production to evolution—must increasingly be executed by AI, improving continuously through real-world operation. Every customer will need this loop, and it must be provided as foundational infrastructure. For us, this means that even if we do not build applications ourselves, we must close the loop from hardware to agents to systems on our own platform. Just as autonomous driving required a tightly coupled perception–decision–action flywheel, the future of software requires an agent-native system built on our hardware. This inevitably demands ownership of three core layers: a foundational model, a cloud-like agent toolchain deployed across devices, and a trust, security, and quality framework that ensures reliability at scale. What emerges is a fundamentally new discipline—software engineering as an autonomous process—one for which traditional education is already obsolete and whose best practices are being forged inside leading companies in real time. The pace is unmistakable: tools like Claude Code have gone from launch to de facto gold standard in a matter of months. This is why urgency matters. AI coding is a platform shift on the scale of the internet, mobile, or cloud, and decisions made between 2025 and 2028 will shape competitiveness for the next decade. The old software “whale” is falling, and a new ecosystem is flourishing. The strategic priorities are clear: aggressively adopt L3/L4 AI coding tools immediately; rebuild systems to be agent-native rather than retrofitted; invest in vertical integration to avoid commoditization; develop Human–AI hybrid FDE capabilities for complex deployments; and over the long term, ensure sovereign AI options to avoid structural dependence. The software industry is not dying—it is being reborn. The only real question is whether you will be among those who shape the transformation, or those who are transformed by it.
