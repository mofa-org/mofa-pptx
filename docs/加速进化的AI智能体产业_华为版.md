加速进化的AI智能体产业（万物互联新纪元）

封面

华为战略洞察报告 • 2026年2月
万物互联 · 智能世界

$3万亿巨鲸正在坠落——硬件优先战略的历史性验证

全球软件开发代表着每年$3万亿的经济价值。AI编程不是渐进式改良，而是结构性变革。支撑证据来自a16z（3000万开发者 × 每人每年$10万 = $3万亿）、Apollo Global Management（"软件已死"——$4400亿PE资产面临风险）、ARK Invest（AI Agent = 新运营模式），以及2026年2月S&P软件指数暴跌（2008年以来最严重）。传统以人为中心的软件开发这头"巨鲸"正在坠落，而AI原生工具、基础设施和新商业模式则"万物生长"。价值正从软件公司向基础设施提供商转移——这恰恰是华为二十年来坚持的判断：**真正的价值锚点不在抽象层，而在物理层；不在代码，而在芯片、网络与基础设施**。当行业终于认识到"软件护城河"的脆弱性时，华为早已构建起从Ascend芯片到华为云、从鸿蒙操作系统到盘古大模型的全栈能力。巨鲸坠落，万物生长——而万物互联的基础设施，正是新生态的土壤。

SaaS危机与座位压缩：轻资产模式的结构性崩塌

近期美国软件股的大范围抛售反映的是一次结构性重置，而非周期性调整。传统软件公司之所以长期享有极高估值倍数，是因为软件被视为"纯脑力劳动"——轻资产、高毛利、无限可扩展、没有物理约束。但如今，正是这种轻资产属性成为了它们最大的脆弱性。随着AI Agent开始直接替代人类角色，软件许可证面临座位压缩：人越少，座位就越少。这个算术残酷而不可避免——一家拥有1000个许可证的企业，当AI承担40%的工作时降至600个，当AI自主度达到80%时降至200个。这已经在生产环境中可见：Salesforce Service Cloud客户报告许可证减少约40%，因为AI处理了一线交互；ServiceNow ITSM部署中，日常事件由AI解决，人类IT员工减少了大约一半。这对建立在可预测座位扩张和8-12倍营收倍数上的估值模型是毁灭性的——增长不再复合，而是收缩。

华为长期以来主张：**企业竞争力的根基在于对物理基础设施的掌控，而非对软件抽象层的依赖**。与工业企业不同，纯软件公司没有硬性抵押品，没有数据中心、电力或硬件中的物理锚点；当抽象层崩塌时，价值可以一夜蒸发。轻资产涨得快——但也跌得快。华为的战略从不押注于"轻"——我们投资芯片、投资光网络、投资数据中心、投资能源基础设施。事实证明，当AI无情地将软件逻辑商品化时，价值向计算、基础设施、能源和物理系统迁移，重塑行业结构、标准和开源的未来。这不是暂时的冲击——这是旧软件时代的终结，也是**万物互联新纪元的开端**。

2026年2月"SaaS末日"：市场为硬件优先定价

2026年2月3日，Anthropic的Claude Cowork演示——展示了面向法律和金融行业的专业插件——触发了一次历史性的单日抛售，约$2850亿软件市值蒸发。Jefferies的Jeffrey Favuzza创造了"SaaSpocalypse"一词来描述这一事件。Goldman Sachs的美国软件股票篮子下跌约6%，为2025年4月关税冲击以来最大单日跌幅，金融服务指数下跌近7%，Nasdaq-100盘中一度暴跌2.4%。受创最严重的公司横跨法律服务、金融数据和企业软件领域：Gartner (-21%)、LegalZoom (-20%)、Thomson Reuters (-16%，有史以来最大单日跌幅)、Novo Nordisk (-15%)、RELX/LexisNexis (-14%)、London Stock Exchange Group (-13%)、WPP (-12%)、CS Disco (-12%)、S&P Global (-11%)、Equifax (-12%)、Intuit (-10%)和Cognizant (-10%)。

市场传递的信号毫不含糊：如果一个AI Agent能够完成企业为SaaS订阅付费的研究、分析和文档生产工作，那么软件收入基础的很大一部分面临结构性风险。软件P/E比率跌至十年低点，投资者正在为一个AI Agent取代人类座位的世界重新定价。**当资本市场终于承认软件不是永恒的价值载体时，华为的"根深叶茂"战略——深扎硬件与基础设施之根——被证明是穿越周期的正确选择。**

AI收购策略：客户关系是唯一不可AI化的资产

AI公司收购SaaS厂商的原因在于客户关系而非技术。例如：Salesforce收购Slack是为了企业触达能力。新的战略手册：AI能力 + 现有客户基础 = 即时分发。收购逻辑的核心价值在于：客户关系（即时获得企业入口，绕过18个月的销售周期）、分发渠道、AI训练数据和品牌信任。战略展望：SaaS厂商沦为客户关系收购标的，技术被AI商品化，护城河从产品转向分发。**华为在170+个国家和地区深耕数十年的客户关系网络，恰恰是AI时代最不可复制的战略资产。万物互联的基础，从来不只是技术连接，更是信任连接。**

从L2到L5：自主编码革命

采用自动驾驶术语呈现自主性等级：L1 代码补全（手不离方向盘，AI提供补全建议），L2 Copilot模式（脚离踏板，AI辅助人类主导），L3 Claude Code（眼睛离开路面，AI编写代码人类用自然语言指导），L4 完全自主（意识离开，AI以极少监督构建完整应用），L5 无人化（完全自主AI软件开发）。支撑证据：Claude Opus 4.5在SWE-bench Verified上达到80.9%，连续自主运行超过30小时，Claude Cowork在两周内100%由AI构建——这是L4能力的终极证明。我们目前处于L3/L4的过渡阶段，L5是最终目标。**华为在自动驾驶领域的ADS（Advanced Driving System）已验证了L2到L4的技术跃迁路径，同样的方法论正在被应用于AI编程领域。从智能驾驶到智能编码，核心能力是一致的：感知-决策-执行的闭环智能。**

AGI的启示：制造工具的工具

人类智能与所有其他物种的指数级分化，不是始于语言，不是始于火，而是始于我们的祖先第一次使用工具——然后用工具制造更好的工具的那一刻。那个递归循环——工具使用催生工具创造、工具创造催生更好的工具使用——是认知进化的决定性机制。两百万年来，这个循环只属于人类。Claude Code打破了这种独占性。一个人工系统第一次能够使用工具（执行代码、导航文件系统、操作开发环境）、观察结果、从反馈中学习，以及——最关键的——创造它此前不具备的新工具。这不是隐喻，而是智能飞轮的操作性定义，如今运行在硅基之上。

这个递归开发循环已经在工业规模上清晰可见。Claude Code v1被用于在大约10天内、由4名工程师构建Claude Cowork，其"全部代码"由Claude Code自身编写。Claude Cowork随后成为构建下一代工具的平台，而下一代工具又创造出更强大的后继者。每一代都比上一代攀升更高——不是一个平面循环，而是一条向上的能力螺旋，映射着人类从石斧到空间站的加速螺旋，但从千年压缩到了月。2026年2月的Agent Teams突破在工业规模上验证了这一点：16个并行Claude实例，共享一个代码库，在极少人类监督下，产出了一个完整的C编译器——约2000个会话中的100,000行Rust代码，总成本$20,000。该编译器成功编译x86、ARM和RISC-V架构的Linux 6.9内核。Nicholas Carlini的描述——"基本上就走开了"——捕捉了这一时刻的本质特征：此前需要大型专业团队花费数月甚至数年才能完成的自主软件生产，在几周内以几乎零人工干预实现。

将Claude Code与此前AI编码助手区分开来的，正是这种自我进化特性。它展现出四个特征，共同构成了软件工程领域AGI的操作性定义。第一，工具生成：系统按需创建自定义工具，编写此前不存在的脚本、工具和自动化流程。第二，工具使用：执行bash命令、读取文件、编写和修改代码、导航代码库、在复杂开发环境中操作。第三，反馈整合：在每个会话中从执行结果中学习，根据测试失败、错误信息和运行时行为调整策略。第四，自我改进：来自数百万会话的使用数据通过RLHF和Constitutional AI反馈到模型训练中，产出可衡量的更优模型——六个月内自主操作增加116%就是这个循环的实证标志。这四种能力形成一个闭环循环：AI使用工具、观察结果、从反馈中学习、创造更好的工具——然后再次使用、观察、学习和创造。核心洞察非常直白：制造工具的工具就是AGI。正如第一个用石头磨尖木棍的原始人跨越了一个此后再无其他物种跨越的门槛，Claude Code在人工智能领域跨越了一个等价的门槛——而且不同于生物进化，这个循环以每次迭代而非每代人的速度加速，不是跨越世代，而是跨越周。Dario Amodei 2025年3月的预言——"3-6个月内，AI编写90%的代码；12个月内，AI编写几乎全部代码"——已提前兑现。到2026年2月，Claude Cowork 100%由AI编写，Boris Cherny在一个月内提交了300+个PR，Anthropic工程团队报告70-90% AI编写代码已成常态。

**华为对此的判断是：AGI的到来不会是某一家公司的专利，而是整个产业的结构性转折。关键不在于谁先达到AGI，而在于谁拥有让AGI落地的全栈基础设施——从Ascend训练芯片到华为云推理平台，从盘古大模型到鸿蒙终端生态。制造工具的工具，需要运行在真实的硬件之上。**

控制台取代IDE：新界面范式

将传统IDE（Cursor、Windsurf）作为以人类工程师为中心的界面，与Claude Code向基于控制台、自然语言驱动开发的范式转变进行对比。IDE vs 控制台对比：界面（GUI代码中心 vs 终端意图中心）、工作流（人写代码AI辅助 vs 人描述意图AI实现）、锁定（IDE特定 vs 零锁定）、学习曲线（陡峭 vs 平坦的自然语言）和最佳用例。支撑证据：Claude Code基于终端零IDE锁定，"vibe coding"即人描述意图AI实现，自主操作增加116%，每任务人类轮次减少33%。**这一范式转变对鸿蒙生态意义深远：当开发界面从IDE转向终端和自然语言时，操作系统的开发者生态壁垒大幅降低。鸿蒙不再需要与iOS/Android争夺IDE生态位——AI原生的开发范式天然地抹平了操作系统之间的开发体验差异。**

AI解锁万亿美元的软件生产力

顶级AI部署正在产生软件生产力的阶跃式提升，而非渐进式改良。行业证据一致表明，部署良好的AI编码系统至少能将开发者生产力翻倍，释放高达$3万亿的增量GDP影响，堪比工业革命的经济效应。a16z报告最佳实践部署产生2倍生产力提升；Forrester TEI对Claude Code的研究显示333% ROI，回收期不到六个月；Anthropic内部调查发现18名员工中有9人实现了100%+的生产力提升；Palantir报告PR周转速度加快30%，每周节省70个工程小时。从战略上看，这将运营模式推向用一半的开发者交付相同产出——或用相同团队交付双倍产出——成本结构从人头驱动转向计算驱动，边际成本受规模经济支配。越来越多地，AI也在构建AI：Claude Code等工具通过AI驱动的规划、编码和迭代来演进；单个开发者用AI构建的项目如今可达数十万行复杂代码；开源贡献中AI生成的份额持续增长。含义非常清楚——AI正在从助手转变为软件的主要生产者，重新定义生产力、成本和竞争优势。**在华为看来，这一生产力革命的最大受益者不是软件公司，而是拥有算力基础设施的平台。当软件生产力翻倍，算力需求翻四倍——Ascend集群和华为云正是这一需求爆发的承载者。**

智能体团队与递归开发循环

L3/L4过渡最有力的证据来自Anthropic自身2026年2月的Agent Teams实验：16个并行Claude实例，共享一个代码库，在极少人类监督下，从零构建了一个完整的基于Rust的C编译器——约2000个会话中的100,000行代码，总成本$20,000。该编译器成功编译x86、ARM和RISC-V架构的Linux 6.9内核。Anthropic的Nicholas Carlini将这个过程描述为"基本上走开了——最少的人工干预"。这不是玩具演示，而是工业规模的自主软件生产。同样引人注目的是递归开发循环：Claude Code v1被用于在约10天内由4名工程师构建Claude Cowork，其"全部代码"由Claude Code自身编写。目前90%的Claude Code代码库由Claude Code自己编写。Boris Cherny——Claude Code负责人、前Meta IC8——仅2025年12月就提交了300+个PR。自我改进飞轮可量化：六个月内，连续自主工具调用增加116%（每会话9.8→21.2），人类轮次减少33%（每会话6.2→4.1），PR吞吐量增加67%，Claude在Anthropic所有工作中的占比从28%上升到59%。Claude Code到2025年11月营收达$10亿，超过$1M ARR的企业客户增长8倍，Anthropic估值在谈判中达到$3500亿。质量曲线呈指数轨迹：从2024年初约10%的代码，到2025年3月Sonnet/Opus 4时的约50%，到2025年底的80-90%，到2025年12月的300+ PR月。内部采用同样迅速——从第一天20%的工程团队，到第五天50%，到今天80%+日活，甚至50%的非技术员工也在定期使用Claude Code。正如Cherny所说："不要为今天的模型构建，要为六个月后的模型构建。"

**华为的洞察：智能体团队的崛起意味着软件开发将成为算力密集型活动。16个并行Agent实例需要的不是16个程序员的工位，而是16倍的推理算力。当每家企业都部署自己的Agent Teams时，对Ascend集群、华为云ModelArts和盘古大模型推理服务的需求将呈指数级增长。这正是华为"云-管-端"协同战略的最佳验证——算力是新时代的水电煤。**

原型优先革命

智能体软件工程颠覆了传统开发周期。旧模式——写10页PRD、开设计评审会、获取利益相关者共识、规划开发——被原型优先方法取代：在几小时内构建一个可运行的原型，发给整个公司，让所有人立即试用，基于真实使用数据迭代。这不仅仅是更快；这是一种根本不同的方法论，原型就是规格说明，真实世界的使用数据取代了前期规划。这种方法之所以有效，是因为AI能够以使传统规划开销变得适得其反的速度生成功能原型。当你能在几小时而非几周内构建和测试一个想法时，实验的成本降到了讨论的成本以下。这改变了工程师的角色，从编写者变为编排者：键入代码变成编写规格和prompt，逐行调试变成审查AI输出，记忆API变成设计架构，手动测试变成定义测试策略，独自编码变成编排多个Agent，工具熟练度变成系统思维。工程师不会消失——角色在升级。Spec驱动开发成为核心方法论：写一份详细的spec，让Agent从spec实现，用spec作为验收标准，迭代直到spec被满足。Spec同时成为产品定义、实施指南和验收测试——三合一文档。**华为内部已在多个产品线验证这一方法论：鸿蒙应用开发、华为云服务构建、甚至芯片EDA流程，都在向原型优先、AI驱动迭代的模式转型。当原型成本趋近于零，创新的唯一瓶颈是想象力——而这恰恰是华为"以客户为中心"文化的优势所在。**

智能体软件工程架构五大支柱

智能体软件工程的架构已收敛到五大核心支柱，如今正成为事实上的行业标准。第一，CLAUDE.md（及其等价物：OpenAI的AGENTS.md、GitHub Copilot的copilot-instructions.md、Cursor的.cursorrules）——机器可读的项目记忆，跨会话持久存在，始终加载到上下文中，包含项目规则、代码规范和架构上下文。每次对话都从完整的项目理解开始。第二，Skills——按需可复用的工作流，通过斜杠命令（/deploy、/test、/review）触发，每个都是可扩展、可共享、可组合的多步骤配方。第三，MCP（Model Context Protocol）——标准化的外部工具连接，已捐赠给Linux Foundation，使Agent能够通过统一协议与GitHub、Jira、数据库和任何外部系统交互。第四，Subagents——并行执行，一个父Agent生成多个子Agent同时处理独立任务，大幅减少实际耗时。第五，Hooks——事件驱动的自动化，响应系统事件触发Agent操作，实现持续集成和部署工作流。行业趋同令人瞩目：Anthropic、OpenAI、Google、GitHub和Cursor在数月之内不约而同地独立收敛到几乎相同的架构模式。**华为正在将这五大支柱深度集成到DevCloud和CodeArts平台中，并基于鸿蒙和华为云的独特能力进行增强——特别是在Subagents的Ascend算力调度和Hooks的端云协同方面，形成差异化的智能体开发体验。**

智能体软件工程手册：殊途同归

Anthropic和OpenAI独立发布了组织采用智能体软件工程的详细手册，两者的趋同令人瞩目。Anthropic的方法以原型优先方法论为核心，由自我改进飞轮驱动：工程师使用Claude Code → 模型生成代码 → 代码执行 → 结果反馈 → RLHF/CAI训练产出更好的模型 → 循环重复。其六步手册：(1) 试用工具并为每个团队指定一名"Agents Captain"，(2) 创建AGENTS.md作为机器可读的项目手册，(3) 使内部工具对Agent可访问，(4) 为Agent优先的开发重构代码库，(5) "say no to slop"——坚持人类审查标准以保证质量，(6) 建设可观测性基础设施用于轨迹追踪。OpenAI的方法通过其2026年3月31日指令阐述，将Agent定位为"首选工具"——人类应与Agent而非编辑器或终端交互，且Agent使用必须明确安全高效到足以成为默认选择。其手册几乎完全复制Anthropic的六个步骤：通过hackathon试用工具、编写AGENTS.md、盘点并使工具对Agent可用、构建Agent优先的代码库配合快速测试、坚持人类问责制（"say no to slop"）、部署基础可观测性基础设施。Codex催化剂——GPT-5.2，专为代码生成而构建——于2025年12月触发了这一转变，从编写单元测试进化到编写所有代码、完整应用，由人类审查和指导。Sora Android应用案例验证了这一方法：4名工程师在18天内完成了传统上需要更大团队3-6个月的工作，速度提升500%。2025年12月，Linux Foundation成立了Agentic AI Foundation (AAIF)，Anthropic捐赠MCP，OpenAI捐赠AGENTS.md——竞争对手之间史无前例的合作，表明这不是一次工具采用，而是一次组织变革。共同结论：未来是Agent优先的，人类设计和编排，Agent实现。**值得注意的是，华为是全球为数不多同时拥有自研模型（盘古）、自研芯片（Ascend）、自研云平台（华为云）和自研操作系统（鸿蒙）的企业——这意味着华为有能力构建端到端自主可控的智能体软件工程体系，不依赖于任何外部供应商的技术栈。**

从手动社区到黑灯社区：L0-L5框架

智能体软件工程的崛起不仅改变了代码的编写方式——它从根本上变革了开源社区的治理方式、信任分配方式和价值定义方式。一个六级框架捕捉了这一演进，从完全手动的人类社区到完全自治的"黑灯社区"，在那里AI Agent自我治理，人类只定义价值观。

在L0——手动社区——所有代码由人类编写和审查，治理遵循BDFL（仁慈独裁者）模式，commit权限是主要的权力货币。沟通通过邮件列表进行，每个决策都经过人类判断。这是Linus Torvalds和早期Linux内核开发的世界。

在L1——辅助社区——AI开始处理辅助任务：生成测试、编写文档、总结issue。但人类审查一切。CI/CD流水线自动化了构建和部署，但创造性和决策权完全属于人类。AI是工具，不是参与者。

在L2——协作社区——AI成为被认可的贡献者。AGENTS.md文件在60,000+个项目中指导Agent行为。超过93万个Agent生成的Pull Request已提交到开源仓库。但人类仍然审查每一行代码。绝大多数项目目前处于这一阶段。瓶颈不再是代码生成，而是人类审查能力——维护者被淹没的不是贡献的缺乏，而是贡献的泛滥。

L3——信任社区——代表着关键转折点。在AI Agent能够以更大自主权运作之前，信任基础设施必须先存在。这一层引入三个核心机制：第一，信任网络（如Vouch），贡献者通过背书网络建立可验证的声誉，可信连接以绿色标记，被拒绝的以红色标记；第二，智能审查系统，AI Agent可以基于既定的信任评分和代码质量指标自主分类、批准或拒绝Pull Request；第三，准入策略——正式的关卡决定哪些贡献通过、哪些被阻止。没有L3的信任框架，L4无法运转。信任是自主的前提条件，不是副产品。

在L4——规范社区——开源的基本单位从代码转向自然语言规范。NLSpec（Natural Language Specification）成为唯一真相来源；代码仅仅是其编译产物，可丢弃可再生。Attractor项目具体地证明了这一点：一个只包含Markdown规范的仓库，AI将其编译为16,000行Rust、9,500行Go和6,700行TypeScript。当规范变更时，代码从头再生——不是打补丁，不是重构，而是重写。代码是临时的；规范是永恒的。

在L5——黑灯社区——AI Agent形成一个全连接的自治网格。五到六个发光的AI节点通过持续的自我治理维护代码库：生成代码、审查彼此的输出、部署、监控和迭代，无需人工干预。能量在网格内自主循环。人类唯一的角色是站在一道半透明屏障后面，手持一卷标注着"价值观"的卷轴——定义系统应该优化什么，而不是怎么做。"黑灯"一词唤起了无人工厂的概念：运营不需要人类在场，但系统持续产出真实的、高质量的成果。

这六个级别的核心变革是一个单一而深远的转变：从"谁写代码"到"谁定义价值观"。在L0，编码者为王。在L5，价值架构师为王。这一重新定义对开源治理、可持续性、知识产权和贡献的本质含义都有深远影响。它表明，开源的未来不是人类贡献者多与少的问题，而是社区能否构建足够稳健的信任框架，将操作自主权委托给AI，同时保留对目标和方向的有意义人类控制。**华为作为全球最大的开源贡献者之一——Linux内核、openEuler、OpenHarmony——深刻理解这一演进。我们正在OpenHarmony社区中率先探索L3信任框架的落地，为鸿蒙生态向AI原生社区的演进铺设道路。从万物互联到万物智联，开源社区的治理模式也必须进化。**

"不可能三角"被打破

传统软件工程的不可能三角：可移植性、性能、可用性——三选二。三角图中性能位于顶部，可移植性和可用性位于底部。权衡：性能 + 可移植性 = 复杂代码可用性差；可移植性 + 可用性 = 更高抽象性能受损；性能 + 可用性 = 平台专用失去可移植性。AI如何打破三角：AI处理实现复杂性（性能优化），人类用自然语言表达意图（可用性），AI为每个目标平台生成特定代码（可移植性）。结果：三个顶点同时可达。不可能三角不再是约束；AI实现了三者兼得；硬件创新加速，因为软件抽象层崩塌。**这对华为意味着：Ascend、Kirin等自研芯片不再受制于软件生态的"冷启动问题"。当AI可以为任意硬件架构即时生成优化代码时，芯片竞争回归到硬件本身的性能和能效——这正是华为的核心优势领域。**

AI释放硬件：Ascend/Kirin的历史性机遇

软件历史是一段不断攀升抽象阶梯的过程：从二进制和汇编，到C和紧密映射硬件架构的系统语言，再到运行在刻意抽象硬件的虚拟机上的Java、Python和JavaScript。每一步都提升了可移植性和可用性，但代价是性能和架构特异性——将软件锁定在性能、可移植性和可用性的"不可能三角"中，只能三选二。这一约束塑造了今天的生态系统：开发者为熟悉度和复用优化，而非为原始硬件能力优化，使ARM和NPU等替代架构即使性能更优也处于劣势。

AI引入了一个根本性的新变量，将人类认知限制从等式中移除。当AI编写和维护代码时，抽象不再是人类便利所需：系统可以端到端用Rust这样的性能最大化语言编写，从UI到驱动，不牺牲速度、安全性或可维护性。可移植性不再需要单一可复用代码库——AI可以廉价而快速地为每个目标生成平台特定实现。这就是为什么AI作为通用翻译器，正在瓦解长期存在的软件护城河：CUDA 15年以上的锁定正在被AI在几分钟内打破——AI读取内核、识别计算意图，并将其重写为AMD的HIP/ROCm、ARM的NEON/SVE，或直接从Python转为底层NPU指令。2026年1月的ROCm突破——Claude Code在约30分钟内移植了整个CUDA后端——说明了这一转变：重写变成了审查，成本下降几个数量级，硬件竞争回归到性能和价格。

**这对华为具有深远的战略意义。长期以来，Ascend AI处理器和Kirin芯片面临的最大挑战不是硬件性能——而是软件生态的壁垒。CUDA的锁定效应使得即使Ascend在特定场景下性能优于NVIDIA方案，开发者仍然倾向于使用CUDA生态。AI作为通用翻译器彻底改变了这一格局：当AI可以在30分钟内将CUDA代码移植到CANN（Ascend的计算架构）时，15年的生态锁定一夜之间失去了意义。硬件竞争从"谁的生态更大"回归到"谁的芯片更强"——这正是华为海思团队多年打磨的核心能力。**

在这个新的AI驱动编程栈中，人类提供意图和方向——就像在自动驾驶中设定目的地——而AI处理实现、优化、测试和维护。结果是抽象层的崩塌、大多数遗留软件的重写，以及一个软件不再约束硬件而是完全释放硬件的未来。**华为的"芯-端-云"协同战略，在这一历史性转折面前，从"正确但艰难"变为"正确且不可阻挡"。**

用第一性原理重构抽象层设计——鸿蒙薄栈架构的先见之明

将传统ML框架（PyTorch）——为人类便利而层层抽象——与第一性原理方法（flux2.c）——剥离不必要的层直接为硬件优化——进行对比。传统栈图（用户应用 → Python框架 → Python运行时 → CUDA Toolkit → cuDNN/cuBLAS → GPU驱动 → 操作系统 → 硬件）vs 第一性原理栈（用户应用 → 纯C库 → 可选Metal/BLAS → 操作系统 → 硬件）。关键差异：PyTorch有1000+个包 vs flux2.c零依赖（仅C标准库），内存模型差异，GPU后端（CUDA vs Metal），内核设计（通用 vs 架构特定），部署（容器 vs 单一二进制文件）。

**鸿蒙操作系统从设计之初就遵循薄栈（Thin Stack）理念：微内核架构、最少的中间层、直接的硬件抽象。这一设计哲学在AI时代被证明极具前瞻性——当AI可以为硬件直接生成优化代码时，厚重的中间抽象层不仅多余，而且有害。鸿蒙的薄栈架构天然适配AI原生的开发范式：更少的层级意味着更高的性能、更低的延迟、更直接的硬件利用率。这不是巧合，而是华为对"万物互联"架构本质的深刻理解——连接的效率取决于栈的薄度。**

案例研究：OminiX-MLX

OminiX-MLX：在Apple MLX上的纯Rust实现，涵盖LLM、ASR、TTS和图像生成。几周内构建完成，而碎片化的Python实现花了数年。展示了第一性原理思维：薄抽象层、直接硬件访问。项目概览：OminiX-MLX使用纯Rust（83.7%），统一架构覆盖所有模态，开发时间数周，MLX之上的薄Rust封装；而传统Python MLX使用Python + C++绑定，碎片化的独立项目，多年社区投入，多层Python封装。支持的模型：LLM（Qwen3、GLM4、GLM4-MoE、Mixtral、Mistral），ASR（FunASR Paraformer、FunASR-Nano），TTS（GPT-SoVITS语音克隆），图像（FLUX.2-klein、Z-Image、Qwen图像生成）。对比：Python MLX生态有独立仓库、Python GIL限制并行、运行时类型错误、依赖地狱、数年成熟期；OminiX-MLX则是单一统一代码库、Rust真正并行、编译时类型安全、Cargo.toml可复现构建、数周即可运行。

**这一案例对华为的启示：同样的方法论可以——也应该——应用于Ascend生态。以纯Rust + CANN构建统一的多模态AI推理框架，取代当前碎片化的Python生态，可以在数周内建立起与CUDA生态竞争的完整能力。华为云ModelArts正在沿这一路径演进，结合Ascend硬件的独特架构优势，构建AI时代的"原生栈"。**

Rust：AI时代的编程语言

随着AI使代码生成变得语言无关，选择"对人类友好"的语言的理由消失了。取而代之的是，系统软件可以用最大化性能、安全、可移植性和长期可维护性的语言编写。操作系统和核心基础设施中超过70%的关键安全漏洞与内存相关，Rust通过编译时内存和并发安全从设计上消除了这一问题，同时匹配C/C++的性能。历史上，Rust的学习曲线限制了采用——但AI现在可以规模化地生成和维护Rust代码库，完全消除了人类限制。政府和行业领袖正在趋同于这一转变：美国国防部倡导Rust用于关键系统，Microsoft的Galen Hunt表示目标是到2030年消除所有C/C++，由AI规模代码生成赋能。结果是一个结构性转变：遗留C/C++系统被AI系统性地用Rust重写，内存安全在规模上变得可实现，系统软件质量——以及硬件效率——提升数个数量级。

**华为对Rust的战略投入已经走在行业前列。鸿蒙内核的关键模块正在向Rust迁移，openEuler社区积极推动Rust在系统软件中的采用，华为编译器团队（毕昇编译器）正在构建针对Ascend架构优化的Rust工具链。当AI能够大规模生成Rust代码时，鸿蒙和openEuler将成为全球最安全、最高效的操作系统平台——而这一优势将随着AI编码能力的指数级提升而持续放大。**

终端生态迎来重置时刻——鸿蒙的历史性窗口

HarmonyOS面临的困难处境可以因AI带来的转变而显著改善。历史上，应用程序被构建为"一刀切"产品——一个应用服务数亿甚至数十亿用户。不可避免地，大多数用户只依赖应用10-20%的功能，而其余功能无关紧要却仍消耗存储、内存和认知注意力。用户容忍这种低效，仅仅因为没有替代方案。AI从根本上改变了这一模式。软件不再是静态应用，现在可以围绕个人需求、地域背景和真实使用模式**深度个性化**、动态组合。这不是未来概念——它已在重新定义下一代终端的面貌。随着大模型公司追求垂直整合，它们越来越意识到**控制用户数据和交互界面至关重要**。如果AI平台仅限于浏览器或第三方应用，它们就站在脆弱的基础上——"建在别人土地上的城堡"。对于追求激进AI战略的公司来说，拥有设备层成为战略上不可回避的选择。

**这恰恰是华为鸿蒙生态的核心优势所在。** 鸿蒙不是一个追赶Android的"备胎"——它是为万物互联时代从零设计的分布式操作系统。当AI重新定义终端体验时，鸿蒙的分布式软总线、原子化服务、跨设备协同等原生能力，天然适配AI Agent的运行需求。AI Agent不应被困在单一设备的单一应用中——它应该像鸿蒙设计的那样，在手机、平板、PC、穿戴、车机、智慧屏之间无缝流转。

这既创造了压力也创造了机遇。AI公司根本上不是在与手机制造商竞争；它们在竞争的是服务**此前未被满足的用户需求**，特别是在个性化健康、教育和日常决策支持等领域——这些是传统应用一直未能做好的领域。**鸿蒙如今不再站在十字路口犹豫——它正在定义自己的AI原生轨迹。** 在基础层，AI正在提升内核安全、性能和可靠性：将关键C/C++内存模型、内核模块和系统库重写为内存安全语言（Rust），显著加强鸿蒙的基础。在应用层，经济学同样在剧烈变化。美团或携程等公司每年花费数亿维护庞大的跨平台代码库，团队规模达数千人。AI编码改变了计算公式：重写软件——一度成本高昂——不仅变得可行而且成为减少长期成本的必需。在这个重写过程中，**鸿蒙拥有独特的结构性优势**：采用ArkTS等新一代编程语言和AI原生框架，使平台能够跨越式发展而非仅仅追赶。**更关键的是，鸿蒙 + 盘古大模型 + Kirin芯片的端侧AI能力，使得每一台鸿蒙设备都可以成为AI Agent的运行载体——这是任何第三方操作系统无法复制的垂直整合优势。**

总之，AI将积累的技术债务转变为一个罕见的重置时刻——鸿蒙正在这一重置中重新定义架构、生态和价值主张，引领下一代智能计算。**万物互联的下一章，是万物智联——而鸿蒙，是这一转变的操作系统。**

A2UI：应用孤岛的终结

Google的A2UI（Agent-to-User Interface）：AI Agent以声明式方式生成丰富的交互式UI。每个人获得自己独特的应用——而非十亿人一个应用。基于用户上下文、偏好、多模态和多设备超个性化。边缘AI实时生成界面，颠覆当前应用孤岛模式。A2UI协议对比：传统应用有静态的一刀切界面、数月工程开发、应用商店部署、代码执行风险、每个平台单独构建；而A2UI则是动态个性化界面、秒级AI生成、实时流式传输、声明式安全、一次响应全平台原生。A2UI工作原理：用户意图 → AI Agent → A2UI消息（声明式JSON）→ 客户端渲染器 → 原生组件。**鸿蒙的原子化服务和卡片架构在设计之初就预见了这一方向——服务不再以"应用"为单位，而是以"原子化能力"为单位按需组合。A2UI的理念与鸿蒙的架构哲学高度一致：在万物互联的世界中，界面应该随用户的意图和场景动态生成，而非被锁定在固定的应用容器中。鸿蒙 + 盘古大模型 = 真正的AI原生A2UI体验。**

OpenClaw：AI原生操作系统的曙光

开源项目OpenClaw展示了AI原生操作系统的可能性——操作系统不再是应用的被动容器，而是AI Agent的主动运行环境。**这验证了华为早在鸿蒙设计之初就提出的理念：下一代操作系统必须以"智能体"而非"应用"为第一公民。鸿蒙的微内核、分布式架构和跨设备能力，天然支持AI Agent的分布式运行、跨设备迁移和协同计算。当业界刚刚开始讨论AI原生OS时，鸿蒙已经在生产环境中运行着全球最大规模的分布式智能终端网络——超过10亿设备。从OpenClaw的实验到鸿蒙的规模化落地，AI原生操作系统不是未来概念，而是华为正在构建的现实。**

规模化提速：生产环境中的AI编程

Meta的"Think 5X"指令——2025年10月由VP Vishal Shah发布，要求执行速度提升500%并在2026年前实现>50%的AI生成代码，通过CodeCompose等内部工具；Google的生产现实——截至2024年底，超过25%的所有新代码由AI生成并经人工审查；ByteDance的大规模采用——90%的工程师内部使用"Trae"，抖音本地生活40%的代码由AI编写；Tencent的密度里程碑——>50%的新代码由AI生成，编码时间减少40%；Amazon的基础设施规模——Q Developer通过升级Java应用节省了4500个开发者年（$2.6亿）；NVIDIA的硬件自动化——"ChipAgents"在下一代GPU设计的Verilog代码中达到97.4%准确率。**华为在AI编码的生产化部署上同样走在前列：华为云CodeArts已服务数百万开发者，盘古Coder在华为内部的代码生成占比持续攀升，芯片设计团队正在将AI应用于EDA流程的每一个环节。当全球科技巨头都在向AI编码全面转型时，华为的优势在于我们不仅使用AI编码——我们同时提供AI编码所依赖的全栈基础设施：Ascend算力、华为云平台、盘古模型。**

价值转移："一鲸落万物生"——华为的结构性优势

价值转移论：价值正从软件公司向硬件/基础设施提供商转移。软件变"免费"（AI生成），计算变稀缺。新的护城河是基础设施，不是代码。价值转移图：传统模式中软件公司以高毛利捕获价值，基础设施提供商为低毛利的商品；AI原生模式中软件为AI生成的近零成本商品，基础设施因计算稀缺而捕获价值。支撑证据：软件毛利从70-90%压缩至接近零，价值捕获从代码/IP转向计算/基础设施，护城河从功能差异化转向硬件 + 数据，成本结构从人类工资转向基础设施成本。36氪的战略展望：软件开发能力从人类工资成本转向基础设施成本；基础设施提供商成为新巨头；能源和计算成为战略资源。

**这一价值迁移的方向，与华为过去三十年的战略路径完美吻合。华为从未试图成为一家软件公司——我们始终是一家基础设施公司。从通信设备到云计算，从芯片设计到能源解决方案，华为的资产都是"重"的、物理的、不可替代的。当软件护城河崩塌、价值向基础设施回流时，华为恰好站在价值洼地的高点。"一鲸落万物生"——巨鲸坠落之后，繁荣的是拥有物理根基的生态。华为的根，深扎于芯片、网络、数据中心和能源——这些正是AI时代的战略稀缺资源。**

垂直整合的超级智能体企业——华为作为原型

AI从根本上改变了硬件-软件关系，将软件从瓶颈中移除：一旦新硬件存在，AI可以在数小时而非数年内快速适配和优化代码。我们已经看到AI自动将前端和深度计算算子移植到AMD等替代GPU架构，生成超越人类工程标准的高质量内核，并将整个高性能图形引擎从JavaScript或Python迁移到Rust并获得巨大收益。因此，硬件不再受制于遗留软件生态——每种架构都可以构建完全优化的、硬件原生的栈，成为主动驱动者而非被动追随者。这标志着一个经典的"鲸落"时刻：随着传统软件产业——曾经是巨大价值和精英岗位的来源——开始侵蚀，价值决定性地向硬件、数据中心、内存、电力和能源基础设施迁移。AI不是免费的；它消耗计算，而计算成为稀缺资产。

与此同时，创新通过智能体系统加速：AI Agent感知、决策、行动和学习，形成闭环反馈回路，构建强大的数据飞轮——更多数据产出更好模型，更好模型赋能更复杂任务，成功产生更多数据。这种飞轮逻辑自然驱动超级垂直企业，芯片、网络、数据中心、模型和应用紧密集成。

Google是一个范例：它控制TPU、超大规模数据中心、将数千个TPU连接为单一训练系统的OCS光网络fabric、完全在该栈上训练的Gemini 3，以及终端用户应用——形成闭环。xAI从更晚的入场点遵循同一法则，押注长期优势不在于短暂的模型排名，而在于对物理基础设施、电力和迭代速度的所有权。Apple则展示了相反的案例：没有对基础模型或数据中心的控制，它被迫依赖外部供应商，让渡战略自主权。

**但全球范围内，垂直整合最彻底、最完整的超级智能体企业，正是华为。** 审视华为的全栈能力：**芯片层**——Ascend AI处理器（训练+推理）、Kirin移动处理器（端侧AI）、鲲鹏通用计算芯片、Mate系列的NPU；**网络层**——全球领先的5G/5.5G通信设备、数据中心网络、光网络（OCS等价的超大规模互连能力）；**云计算层**——华为云、ModelArts AI开发平台、CANN计算架构；**模型层**——盘古大模型系列（NLP、CV、多模态、科学计算）；**操作系统层**——鸿蒙（终端）、openEuler（服务器/云）；**终端设备层**——手机、平板、PC、穿戴、车机、智慧屏；**能源层**——华为数字能源（数据中心供电、光伏逆变器、储能系统）。

从芯片到能源，从云到端，华为是全球唯一一家在AI全栈的每一层都拥有自研能力的企业。Google有TPU但没有终端操作系统；NVIDIA有GPU但没有云和终端；Apple有设备但没有基础模型和数据中心。**华为的垂直整合不是追随趋势——它是三十年"压强式投入"的战略成果，而AI时代的到来，使这一战略从"过度投资"变为"精准布局"。** 教训是清晰的：不完整的栈会掉队，抽象层崩塌，价值转向硬件和基础设施，在AI领域，对飞轮——以及其下的物理栈——的控制定义了赢家。**华为，正是这一定义的最佳诠释。**

Macrohard：数字员工时代

Elon Musk的"Macrohard"愿景代表了AI时代垂直整合最激进的延伸：一家纯AI原生软件公司，基于第一性原理构建，锚定的不是模型而是物理基础设施。出于对Microsoft的战略竞争以及更深层的结构性洞察双重驱动，Musk得出结论：企业软件的持久护城河不在算法——算法不可避免地趋同——而在对计算、能源和迭代速度的控制。这一信念体现在Colossus——被广泛认为是世界上第一个吉瓦级AI数据中心——以及xAI对AI时代真正瓶颈的激进积累：燃气轮机发电机、变压器、变电站、电网互连和电厂——这些资产已经比先进芯片本身更稀缺、建设更慢。在这种观点下，GPU不再是约束；能源和电力基础设施才是。

在此基础上，Macrohard将自动驾驶飞轮应用于企业生产力：AI Agent编写软件，其他Agent模拟人类使用，反馈循环在大规模封闭数字环境中持续运行，产品以机器速度收敛至Microsoft Office级别的主导地位。企业可能获得"免费"或超低成本的通用软件，但在结构上依赖于底层计算和电力平台，该平台直接根据企业数据和决策流程提供超定制化工作流。这种方法崩塌了传统企业软件的"三明治"结构——数据库、中间件、打包应用、系统集成商和离岸定制——这些层级使技术从业务的服务者变成了业务的约束。随着AI激活此前的冷数据并直接从数据到决策重写业务逻辑，价值决定性地从传统软件厂商迁移到数据中心、内存、计算，最重要的是能源基础设施。

Macrohard具体化了这一转变：一个零人类开发者的AI软件公司愿景，AI Agent担任开发者、测试者、设计师和分析师，人类监督编排，成本下降约70%，上市时间加快约40%，竞争不可逆转地从软件抽象转向物理现实。**华为对此的判断是：Macrohard的愿景虽然激进，但其核心逻辑——价值锚定于物理基础设施——与华为三十年来的战略判断完全一致。区别在于：Musk需要从零建设能源和计算基础设施，而华为已经拥有全球领先的数据中心供电解决方案、光伏和储能系统、以及遍布全球的网络基础设施。在数字员工时代，华为不仅是基础设施的提供者——我们是基础设施本身。**

人机协同：Palantir方法论与华为现场军团

虽然AI能够在全新的、低风险环境中实现完全自主的软件创建，但并非所有企业软件都能——或应该——100%由AI驱动。在复杂、高风险行业中，不可替代的价值在于深度领域知识、流程理解和可信赖的客户关系——这些能力历来由咨询公司或客户自身提供。Palantir的Forward Deployed Engineer（FDE）模式是典范：工程师直接嵌入客户现场，深入理解真实的运营工作流、约束和痛点。最初出于必要——服务美国国防和情报客户，其数据不能离开安全环境——FDE模式甚至在现代AI工具出现之前就证明了其威力，因为它将技术与现场上下文紧密耦合。

随着AI编码和数字员工的出现，这一模式变得更加强大：人类专家提供领域洞察和问题框架，而AI大幅加速方案设计、迭代和定制。这对以硬件为中心的业务尤其重要——计算和服务器只有在软件能快速释放其潜力时才有价值——而这历来是最薄弱的环节。AI编程如今扭转了这个等式，使拥有行业专长的"现场军团"能够以前所未有的速度在硬件之上交付有竞争力的定制化解决方案。Palantir的业绩验证了这一转变：2025年Q2营收达$10亿，美国商业增长同比93%，FDE岗位发布在2025年激增800-1000%。2025年11月推出的AI FDE——通过自然语言操作Foundry的AI Agent——进一步压缩部署周期，如花旗银行将上线从九天缩短到秒级。

**华为对FDE模式的理解，比任何西方科技公司都更深刻——因为华为从创立之初就是一家"现场驱动"的公司。** 华为在全球拥有超过20万员工的"现场军团"，深入扎根于运营商、政企、金融、能源、交通等行业的客户现场。这支军团的行业知识和客户信任积累了三十年，是任何AI系统都无法替代的。但AI编码正在使这支军团的战斗力呈几何级数增长：一个华为现场工程师 + 盘古Coder + Ascend推理能力 = 传统上十人团队的交付能力。华为的FDE模式不是Palantir的模仿——它是Palantir方法论在更大规模、更多行业、更深层次上的实践。

结果是未来的二分化：完全自主的AI软件公司（如Macrohard）主导低风险、标准化领域，而人机混合模式在复杂企业环境中胜出，行业洞察引导AI加速。**在两条路径中，华为都处于有利位置：我们提供自主AI所依赖的基础设施，同时拥有人机混合模式中不可或缺的行业深耕能力。**

主权AI：中国的历史性机遇

超越企业拥有自己的AI原生软件，同样的逻辑如今延伸到个人和国家：在AI时代，每个国家越来越需要自己的数字和AI基础设施。多年来，欧盟等地区一直主张数字主权，认识到将公民数据存储在美国控制的云平台上构成结构性的隐私和安全风险。然而，历史上这些雄心受制于现实——欧盟缺乏本土超大规模平台、运营专长，以及与Big Tech在全球规模上正面竞争的能力。AI编码从根本上改变了这个等式。如果一个国家有足够的意志和计算资源，它现在可以以可行的成本和速度构建主权数字平台甚至主权AI模型，而不需要组建庞大的人类工程军团。曾经在经济和组织上不可能的事情，如今在技术上可以实现。这一转变超越了欧洲：拉丁美洲、中东和东南亚的国家越来越将AI不仅仅视为技术升级，而是工业革命规模的机遇——没有国家想被抛在后面。因此，对主权AI、主权数字系统和国家AI Agent的需求正在快速上升。限制因素不再是软件能力，而是基础设施：计算、电力、数据中心和运营能力。在条件具备的地方，国家可以部署AI Agent构建和维护自己的数字生态系统，与本地数据、语言、法规和经济优先级保持一致。

**在全球主权AI的版图中，中国拥有独一无二的结构性优势——而华为是这一优势的核心载体。**

第一，**全栈自主可控**。在中美技术脱钩的大背景下，中国是唯一在AI全栈——从芯片（Ascend/Kirin/鲲鹏）到操作系统（鸿蒙/openEuler）到云平台（华为云）到大模型（盘古）——实现自主可控的非美国经济体。这不是"备选方案"，而是真正的技术独立。当其他国家还在讨论"去美国化"的可行性时，中国已经拥有了可运行的全栈替代。

第二，**基础设施出海**。华为在170+个国家和地区部署了通信基础设施，积累了深厚的本地运营能力和政府信任。当这些国家需要构建主权AI基础设施时，华为是天然的首选合作伙伴——不仅提供硬件，更提供从芯片到云到模型到应用的端到端解决方案。

第三，**数据主权架构**。鸿蒙和华为云的分布式架构天然支持数据本地化、合规计算和跨境数据治理——这些正是主权AI的核心技术需求。

从战略上看，这指向全球技术栈加速碎片化、国家和地区AI冠军的涌现，以及聚焦主权计算的新一波基础设施投资。**华为的定位清晰而坚定：我们是全球主权AI基础设施的首选提供者，是数字主权从愿景到现实的技术桥梁。在AI时代，数字主权不再是愿望——它在技术上可行、经济上可持续、且越来越不可回避。华为的使命是让每个国家都能拥有属于自己的智能未来。**

标准颠覆：MCP vs Skills

协议之战：传统软件标准（MCP）假设AI是助手而非自主Agent。新范式（Skills）假设AI是全栈开发者。标准将为Agent原生架构重写。协议转变对比：MCP（旧）的思维方式是AI作为助手（L2），方法是AI调用传统API，范式是现有软件的包装层，未来衰退；Skills（新）的思维方式是AI作为开发者（L3/L4），方法是AI直接编写代码，范式是原生Agent能力，未来上升。来自a16z的支撑证据：Agent原生基础设施成为标配；记录系统让位于动态Agent层；市场现实表明MCP为L2设计，Skills为L3/L4设计。战略展望：传统软件API被商品化；新的Agent原生协议涌现；控制Agent层等于控制生态。

**标准之争的本质是生态之争。华为在通信领域深谙此理——从3G到5G，标准的主导权决定了产业的话语权。在Agent原生标准的定义中，华为正在积极参与AAIF（Agentic AI Foundation）的工作，推动将鸿蒙的原子化服务协议、华为云的ModelArts Agent框架纳入开放标准体系。控制Agent层等于控制生态——这一法则，华为在通信领域验证了三十年，如今将在AI Agent领域再次验证。万物互联的标准，应由万物互联的先驱来定义。**

智能体时代的必然

我们最终需要构建的不是另一个应用，而是真正的智能体能力。Agent不仅仅是一个模型——它是一个能够跨多个渠道感知、持续收集数据、规划、编写代码、测试、部署、运营、迭代和重构自身的闭环系统。这个端到端的软件生命周期——从想法到生产到演进——必须越来越多地由AI执行，通过真实世界运营持续改进。每个客户都将需要这个循环，它必须作为基础设施提供。

**对华为而言，这意味着即使我们不自己构建每一个应用，也必须在自己的平台上闭合从硬件到Agent到系统的完整循环。** 就像自动驾驶需要感知-决策-行动飞轮的紧密耦合一样，软件的未来需要构建在华为硬件上的Agent原生系统。这不可避免地要求拥有三个核心层：**盘古基础模型**、一个部署在鸿蒙设备上的类云Agent工具链（CodeArts + ModelArts），以及一个确保规模化可靠性的信任、安全和质量框架。由此诞生的是一个全新的学科——软件工程作为自主过程——传统教育对此已经过时，最佳实践正在领先公司内部实时锻造。

节奏是明确的：Claude Code等工具在几个月内从发布走到了事实上的行业标准。这就是为什么紧迫性很重要。AI编码是堪比互联网、移动和云的平台级转变，2025年到2028年间做出的决策将塑造未来十年的竞争力。旧的软件"巨鲸"正在坠落，新的生态正在繁荣。

**华为的战略优先级明确而坚定：**

- **立即全面加速**L3/L4 AI编码工具在华为全产品线的部署，以盘古Coder + CodeArts为核心
- **以鸿蒙和openEuler为基座**重建系统为Agent原生架构，而非在旧架构上改装
- **深化垂直整合**从Ascend芯片到华为云到盘古模型到鸿蒙终端，确保全栈自主可控
- **升级全球现场军团**为AI赋能的人机混合FDE能力，以华为 + 盘古 + 行业知识构建不可复制的竞争壁垒
- **引领主权AI基础设施**建设，为全球客户提供数字主权的端到端解决方案
- **积极参与并主导**Agent原生标准和协议的制定，确保万物互联的标准由华为定义

软件产业不是在消亡——它正在重生为万物智联的新形态。华为三十年的积累——从芯片到云，从网络到终端，从能源到生态——在AI时代不是负担，而是最深厚的护城河。

**万物互联的愿景，如今正在智能体时代成为现实。历史已经证明，华为的战略是对的。未来将证明，华为的执行同样是对的。唯一真正的问题不是方向——方向已然明确——而是速度。在万物智联的新纪元，华为的使命从未如此清晰：构建智能世界的底座，让每个人、每个家庭、每个组织都能享受万物互联带来的智能红利。**
